{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import os\n",
    "\n",
    "seed=0\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)\n",
    "#session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "session_conf =tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "#tf.set_random_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "#sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "\n",
    "K.set_session(sess)\n",
    "#----------------------------Reproducible----------------------------------------------------------------------------------------\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Flatten, Activation, Dropout, Layer\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers,initializers,constraints,regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import LambdaCallback,ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import h5py\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "import random\n",
    "import scipy.sparse as sparse\n",
    "import scipy.io\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "#Import ourslef defined methods\n",
    "import sys\n",
    "sys.path.append(r\"./Defined\")\n",
    "import Functions as F\n",
    "\n",
    "# The following code should be added before the keras model\n",
    "#np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_lambda=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"./Dataset/SMK_CAN_187.mat\"\n",
    "Data = scipy.io.loadmat(data_path)\n",
    "\n",
    "data_arr=Data['X']\n",
    "label_arr=Data['Y'][:, 0]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data=StandardScaler().fit_transform(data_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of C_train_x: (149, 19993)\n",
      "Shape of C_train_y: (149,)\n",
      "Shape of C_test_x: (38, 19993)\n",
      "Shape of C_test_y: (38,)\n",
      "Shape of x_train: (134, 19993)\n",
      "Shape of x_test: (38, 19993)\n",
      "Shape of x_validate: (15, 19993)\n",
      "Shape of y_train: (134,)\n",
      "Shape of y_test: (38,)\n",
      "Shape of y_validate: (15,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ny_train_onehot = to_categorical(y_train_)\\ny_validate_onehot = to_categorical(y_validate_)\\ny_test_onehot = to_categorical(C_test_y)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_train_x,C_test_x,C_train_y,C_test_y= train_test_split(data_arr,label_arr,test_size=0.2,random_state=seed)\n",
    "x_train,x_validate,y_train,y_validate= train_test_split(C_train_x,C_train_y,test_size=0.1,random_state=seed)\n",
    "\n",
    "print('Shape of C_train_x: ' + str(C_train_x.shape)) \n",
    "print('Shape of C_train_y: ' + str(C_train_y.shape)) \n",
    "print('Shape of C_test_x: ' + str(C_test_x.shape)) \n",
    "print('Shape of C_test_y: ' + str(C_test_y.shape)) \n",
    "\n",
    "x_test=C_test_x\n",
    "y_test=C_test_y\n",
    "\n",
    "print('Shape of x_train: ' + str(x_train.shape)) \n",
    "print('Shape of x_test: ' + str(x_test.shape)) \n",
    "print('Shape of x_validate: ' + str(x_validate.shape))\n",
    "print('Shape of y_train: ' + str(y_train.shape))\n",
    "print('Shape of y_test: ' + str(y_test.shape))\n",
    "print('Shape of y_validate: ' + str(y_validate.shape))\n",
    "\n",
    "'''\n",
    "y_train_onehot = to_categorical(y_train_)\n",
    "y_validate_onehot = to_categorical(y_validate_)\n",
    "y_test_onehot = to_categorical(C_test_y)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "class Feature_Select_Layer(Layer):\n",
    "    \n",
    "    def __init__(self, output_dim, l1_lambda, **kwargs):\n",
    "        super(Feature_Select_Layer, self).__init__(**kwargs)\n",
    "        self.output_dim = output_dim\n",
    "        self.l1_lambda=l1_lambda\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel',  \n",
    "                                      shape=(input_shape[1],),\n",
    "                                      initializer=initializers.RandomUniform(minval=0., maxval=1.),\n",
    "                                      trainable=True,\n",
    "                                      regularizer=regularizers.l1(self.l1_lambda),\n",
    "                                      constraint=constraints.NonNeg())\n",
    "        super(Feature_Select_Layer, self).build(input_shape)\n",
    "    \n",
    "    def call(self, x, selection=False,k=36):\n",
    "        kernel=self.kernel        \n",
    "        if selection:\n",
    "            kernel_=K.transpose(kernel)\n",
    "            print(kernel_.shape)\n",
    "            kth_largest = tf.math.top_k(kernel_, k=k)[0][-1]\n",
    "            kernel = tf.where(condition=K.less(kernel,kth_largest),x=K.zeros_like(kernel),y=kernel)        \n",
    "        return K.dot(x, tf.linalg.tensor_diag(kernel))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "def Identity_Autoencoder(p_data_feature=x_train.shape[1],\\\n",
    "                         p_encoding_dim=50,\\\n",
    "                         p_learning_rate= 1E-3,\\\n",
    "                         p_l1_lambda=0.1):\n",
    "    \n",
    "    input_img = Input(shape=(p_data_feature,), name='autoencoder_input')\n",
    "\n",
    "    feature_selection = Feature_Select_Layer(output_dim=p_data_feature,\\\n",
    "                                             l1_lambda=p_l1_lambda,\\\n",
    "                                             input_shape=(p_data_feature,),\\\n",
    "                                             name='feature_selection')\n",
    "\n",
    "    feature_selection_score=feature_selection(input_img)\n",
    "\n",
    "    encoded = Dense(p_encoding_dim,\\\n",
    "                    activation='tanh',\\\n",
    "                    kernel_initializer=initializers.glorot_uniform(seed),\\\n",
    "                    name='autoencoder_hidden_layer')\n",
    "    \n",
    "    encoded_score=encoded(feature_selection_score)\n",
    "    \n",
    "    bottleneck_score=encoded_score\n",
    "    \n",
    "    decoded = Dense(p_data_feature,\\\n",
    "                    activation='tanh',\\\n",
    "                    kernel_initializer=initializers.glorot_uniform(seed),\\\n",
    "                    name='autoencoder_output')\n",
    "    \n",
    "    decoded_score =decoded(bottleneck_score)\n",
    "\n",
    "    latent_encoder_score = Model(input_img, bottleneck_score)\n",
    "    autoencoder = Model(input_img, decoded_score)\n",
    "    \n",
    "    autoencoder.compile(loss='mean_squared_error',\\\n",
    "                        optimizer=optimizers.Adam(lr=p_learning_rate))\n",
    "    \n",
    "    print('Autoencoder Structure-------------------------------------')\n",
    "    autoencoder.summary()\n",
    "    return autoencoder,latent_encoder_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_number=1000\n",
    "batch_size_value=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4.1.1 Identity Autoencoder\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Autoencoder Structure-------------------------------------\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "autoencoder_input (InputLaye (None, 19993)             0         \n",
      "_________________________________________________________________\n",
      "feature_selection (Feature_S (None, 19993)             19993     \n",
      "_________________________________________________________________\n",
      "autoencoder_hidden_layer (De (None, 64)                1279616   \n",
      "_________________________________________________________________\n",
      "autoencoder_output (Dense)   (None, 19993)             1299545   \n",
      "=================================================================\n",
      "Total params: 2,599,154\n",
      "Trainable params: 2,599,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ide_AE,\\\n",
    "latent_encoder_score_Ide_AE=Identity_Autoencoder(p_data_feature=x_train.shape[1],\\\n",
    "                                                 p_encoding_dim=64,\\\n",
    "                                                 p_learning_rate= 1E-2,\\\n",
    "                                                 p_l1_lambda=l1_lambda)\n",
    "\n",
    "file_name=\"./log/AgnoSS.png\"\n",
    "plot_model(Ide_AE, to_file=file_name,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 134 samples, validate on 15 samples\n",
      "Epoch 1/1000\n",
      "134/134 [==============================] - 42s 314ms/step - loss: 9303.2202 - val_loss: 8338.0859\n",
      "Epoch 2/1000\n",
      "134/134 [==============================] - 43s 320ms/step - loss: 7680.8934 - val_loss: 6769.5654\n",
      "Epoch 3/1000\n",
      "134/134 [==============================] - 41s 307ms/step - loss: 6174.8578 - val_loss: 5356.1265\n",
      "Epoch 4/1000\n",
      "134/134 [==============================] - 41s 309ms/step - loss: 4828.5640 - val_loss: 4108.6387\n",
      "Epoch 5/1000\n",
      "134/134 [==============================] - 42s 310ms/step - loss: 3651.9910 - val_loss: 3033.9575\n",
      "Epoch 6/1000\n",
      "134/134 [==============================] - 41s 305ms/step - loss: 2648.4462 - val_loss: 2130.2100\n",
      "Epoch 7/1000\n",
      "134/134 [==============================] - 43s 322ms/step - loss: 1811.9310 - val_loss: 1389.0709\n",
      "Epoch 8/1000\n",
      "134/134 [==============================] - 42s 316ms/step - loss: 1136.3922 - val_loss: 807.6744\n",
      "Epoch 9/1000\n",
      "134/134 [==============================] - 44s 328ms/step - loss: 621.4804 - val_loss: 387.4493\n",
      "Epoch 10/1000\n",
      "134/134 [==============================] - 42s 313ms/step - loss: 266.1546 - val_loss: 125.9864\n",
      "Epoch 11/1000\n",
      "134/134 [==============================] - 47s 351ms/step - loss: 71.5209 - val_loss: 27.6903\n",
      "Epoch 12/1000\n",
      "134/134 [==============================] - 47s 353ms/step - loss: 64.4809 - val_loss: 78.7376\n",
      "Epoch 13/1000\n",
      "134/134 [==============================] - 48s 359ms/step - loss: 39.4628 - val_loss: 31.6301\n",
      "Epoch 14/1000\n",
      "134/134 [==============================] - 52s 386ms/step - loss: 43.1473 - val_loss: 68.0596\n",
      "Epoch 15/1000\n",
      "134/134 [==============================] - 53s 392ms/step - loss: 45.9699 - val_loss: 29.0418\n",
      "Epoch 16/1000\n",
      "134/134 [==============================] - 52s 391ms/step - loss: 28.5952 - val_loss: 26.7619\n",
      "Epoch 17/1000\n",
      "134/134 [==============================] - 50s 373ms/step - loss: 27.3581 - val_loss: 26.9087\n",
      "Epoch 18/1000\n",
      "134/134 [==============================] - 50s 373ms/step - loss: 29.2374 - val_loss: 26.4553\n",
      "Epoch 19/1000\n",
      "134/134 [==============================] - 48s 356ms/step - loss: 26.9683 - val_loss: 26.5143\n",
      "Epoch 20/1000\n",
      "134/134 [==============================] - 50s 375ms/step - loss: 26.7363 - val_loss: 26.6881\n",
      "Epoch 21/1000\n",
      "134/134 [==============================] - 50s 370ms/step - loss: 26.7257 - val_loss: 26.4440\n",
      "Epoch 22/1000\n",
      "134/134 [==============================] - 50s 374ms/step - loss: 26.5183 - val_loss: 26.5845\n",
      "Epoch 23/1000\n",
      "134/134 [==============================] - 51s 383ms/step - loss: 26.5126 - val_loss: 26.3913\n",
      "Epoch 24/1000\n",
      "134/134 [==============================] - 50s 372ms/step - loss: 26.5061 - val_loss: 26.4773\n",
      "Epoch 25/1000\n",
      "134/134 [==============================] - 50s 372ms/step - loss: 26.4797 - val_loss: 26.3951\n",
      "Epoch 26/1000\n",
      "134/134 [==============================] - 53s 394ms/step - loss: 26.4620 - val_loss: 26.3968\n",
      "Epoch 27/1000\n",
      "134/134 [==============================] - 49s 364ms/step - loss: 26.4610 - val_loss: 26.4216\n",
      "Epoch 28/1000\n",
      "134/134 [==============================] - 50s 370ms/step - loss: 26.4600 - val_loss: 26.4060\n",
      "Epoch 29/1000\n",
      "134/134 [==============================] - 49s 362ms/step - loss: 26.4560 - val_loss: 26.4143\n",
      "Epoch 30/1000\n",
      "134/134 [==============================] - 50s 376ms/step - loss: 26.4553 - val_loss: 26.4224\n",
      "Epoch 31/1000\n",
      "134/134 [==============================] - 49s 367ms/step - loss: 26.4554 - val_loss: 26.4152\n",
      "Epoch 32/1000\n",
      "134/134 [==============================] - 49s 368ms/step - loss: 26.4546 - val_loss: 26.3853\n",
      "Epoch 33/1000\n",
      "134/134 [==============================] - 47s 353ms/step - loss: 26.4565 - val_loss: 26.4352\n",
      "Epoch 34/1000\n",
      "134/134 [==============================] - 49s 364ms/step - loss: 26.4548 - val_loss: 26.3862\n",
      "Epoch 35/1000\n",
      "134/134 [==============================] - 46s 343ms/step - loss: 26.4575 - val_loss: 26.4529\n",
      "Epoch 36/1000\n",
      "134/134 [==============================] - 47s 349ms/step - loss: 26.4602 - val_loss: 26.3760\n",
      "Epoch 37/1000\n",
      "134/134 [==============================] - 48s 355ms/step - loss: 26.4561 - val_loss: 26.4737\n",
      "Epoch 38/1000\n",
      "134/134 [==============================] - 50s 371ms/step - loss: 26.4668 - val_loss: 26.3718\n",
      "Epoch 39/1000\n",
      "134/134 [==============================] - 48s 361ms/step - loss: 26.4593 - val_loss: 26.4541\n",
      "Epoch 40/1000\n",
      "134/134 [==============================] - 46s 345ms/step - loss: 26.4585 - val_loss: 26.3705\n",
      "Epoch 41/1000\n",
      "134/134 [==============================] - 46s 341ms/step - loss: 26.4609 - val_loss: 26.4672\n",
      "Epoch 42/1000\n",
      "134/134 [==============================] - 45s 339ms/step - loss: 26.4652 - val_loss: 26.3728\n",
      "Epoch 43/1000\n",
      "134/134 [==============================] - 45s 339ms/step - loss: 26.4590 - val_loss: 26.4369\n",
      "Epoch 44/1000\n",
      "134/134 [==============================] - 46s 344ms/step - loss: 26.4671 - val_loss: 26.3674\n",
      "Epoch 45/1000\n",
      "134/134 [==============================] - 46s 347ms/step - loss: 26.4678 - val_loss: 26.4328\n",
      "Epoch 46/1000\n",
      "134/134 [==============================] - 47s 352ms/step - loss: 26.4752 - val_loss: 26.3672\n",
      "Epoch 47/1000\n",
      "134/134 [==============================] - 48s 359ms/step - loss: 26.4707 - val_loss: 26.5357\n",
      "Epoch 48/1000\n",
      "134/134 [==============================] - 46s 342ms/step - loss: 26.4680 - val_loss: 26.3648\n",
      "Epoch 49/1000\n",
      "134/134 [==============================] - 47s 348ms/step - loss: 26.4700 - val_loss: 26.5395\n",
      "Epoch 50/1000\n",
      "134/134 [==============================] - 48s 361ms/step - loss: 26.4535 - val_loss: 26.3682\n",
      "Epoch 51/1000\n",
      "134/134 [==============================] - 49s 367ms/step - loss: 26.4687 - val_loss: 26.4475\n",
      "Epoch 52/1000\n",
      "134/134 [==============================] - 47s 350ms/step - loss: 26.4659 - val_loss: 26.3764\n",
      "Epoch 53/1000\n",
      "134/134 [==============================] - 48s 362ms/step - loss: 26.4506 - val_loss: 26.5423\n",
      "Epoch 54/1000\n",
      "134/134 [==============================] - 47s 354ms/step - loss: 26.4477 - val_loss: 26.4135\n",
      "Epoch 55/1000\n",
      "134/134 [==============================] - 48s 358ms/step - loss: 26.4422 - val_loss: 26.3690\n",
      "Epoch 56/1000\n",
      "134/134 [==============================] - 46s 340ms/step - loss: 26.4363 - val_loss: 26.3873\n",
      "Epoch 57/1000\n",
      "134/134 [==============================] - 46s 343ms/step - loss: 26.4358 - val_loss: 26.3636\n",
      "Epoch 58/1000\n",
      "134/134 [==============================] - 46s 346ms/step - loss: 26.4311 - val_loss: 26.3923\n",
      "Epoch 59/1000\n",
      "134/134 [==============================] - 48s 361ms/step - loss: 26.4330 - val_loss: 26.3596\n",
      "Epoch 60/1000\n",
      "134/134 [==============================] - 46s 344ms/step - loss: 26.4251 - val_loss: 26.4294\n",
      "Epoch 61/1000\n",
      "134/134 [==============================] - 48s 358ms/step - loss: 26.4299 - val_loss: 26.3941\n",
      "Epoch 62/1000\n",
      "134/134 [==============================] - 47s 354ms/step - loss: 26.4260 - val_loss: 26.3851\n",
      "Epoch 63/1000\n",
      "134/134 [==============================] - 49s 365ms/step - loss: 26.4252 - val_loss: 26.3654\n",
      "Epoch 64/1000\n",
      "134/134 [==============================] - 48s 359ms/step - loss: 26.4204 - val_loss: 26.3723\n",
      "Epoch 65/1000\n",
      "134/134 [==============================] - 48s 355ms/step - loss: 26.4234 - val_loss: 26.3751\n",
      "Epoch 66/1000\n",
      "134/134 [==============================] - 51s 384ms/step - loss: 26.4222 - val_loss: 26.3901\n",
      "Epoch 67/1000\n",
      "134/134 [==============================] - 47s 354ms/step - loss: 26.4220 - val_loss: 26.3795\n",
      "Epoch 68/1000\n",
      "134/134 [==============================] - 50s 370ms/step - loss: 26.4211 - val_loss: 26.3595\n",
      "Epoch 69/1000\n",
      "134/134 [==============================] - 49s 365ms/step - loss: 26.4198 - val_loss: 26.3750\n",
      "Epoch 70/1000\n",
      "134/134 [==============================] - 51s 379ms/step - loss: 26.4193 - val_loss: 26.3599\n",
      "Epoch 71/1000\n",
      "134/134 [==============================] - 50s 370ms/step - loss: 26.4142 - val_loss: 26.3704\n",
      "Epoch 72/1000\n",
      "134/134 [==============================] - 51s 383ms/step - loss: 26.4166 - val_loss: 26.3767\n",
      "Epoch 73/1000\n",
      "134/134 [==============================] - 49s 365ms/step - loss: 26.4155 - val_loss: 26.3798\n",
      "Epoch 74/1000\n",
      "134/134 [==============================] - 50s 371ms/step - loss: 26.4163 - val_loss: 26.3638\n",
      "Epoch 75/1000\n",
      "134/134 [==============================] - 47s 354ms/step - loss: 26.4152 - val_loss: 26.3756\n",
      "Epoch 76/1000\n",
      "134/134 [==============================] - 48s 358ms/step - loss: 26.4137 - val_loss: 26.3784\n",
      "Epoch 77/1000\n",
      "134/134 [==============================] - 49s 365ms/step - loss: 26.4143 - val_loss: 26.3729\n",
      "Epoch 78/1000\n",
      "134/134 [==============================] - 49s 368ms/step - loss: 26.4144 - val_loss: 26.3750\n",
      "Epoch 79/1000\n",
      "134/134 [==============================] - 48s 361ms/step - loss: 26.4137 - val_loss: 26.3731\n",
      "Epoch 80/1000\n",
      "134/134 [==============================] - 52s 387ms/step - loss: 26.4123 - val_loss: 26.3645\n",
      "Epoch 81/1000\n",
      "134/134 [==============================] - 57s 424ms/step - loss: 26.4117 - val_loss: 26.3742\n",
      "Epoch 82/1000\n",
      "134/134 [==============================] - 56s 415ms/step - loss: 26.4129 - val_loss: 26.3611\n",
      "Epoch 83/1000\n",
      "134/134 [==============================] - 56s 415ms/step - loss: 26.4112 - val_loss: 26.3693\n",
      "Epoch 84/1000\n",
      "134/134 [==============================] - 54s 405ms/step - loss: 26.4113 - val_loss: 26.3603\n",
      "Epoch 85/1000\n",
      "134/134 [==============================] - 54s 406ms/step - loss: 26.4098 - val_loss: 26.3638\n",
      "Epoch 86/1000\n",
      "134/134 [==============================] - 55s 412ms/step - loss: 26.4103 - val_loss: 26.3621\n",
      "Epoch 87/1000\n",
      "134/134 [==============================] - 52s 391ms/step - loss: 26.4094 - val_loss: 26.3620\n",
      "Epoch 88/1000\n",
      "134/134 [==============================] - 51s 384ms/step - loss: 26.4088 - val_loss: 26.3698\n",
      "Epoch 89/1000\n",
      "134/134 [==============================] - 49s 366ms/step - loss: 26.4087 - val_loss: 26.3640\n",
      "Epoch 90/1000\n",
      "134/134 [==============================] - 48s 360ms/step - loss: 26.4092 - val_loss: 26.3662\n",
      "Epoch 91/1000\n",
      "134/134 [==============================] - 49s 366ms/step - loss: 26.4087 - val_loss: 26.3611\n",
      "Epoch 92/1000\n",
      "134/134 [==============================] - 48s 357ms/step - loss: 26.4082 - val_loss: 26.3619\n",
      "Epoch 93/1000\n",
      "134/134 [==============================] - 48s 359ms/step - loss: 26.4084 - val_loss: 26.3654\n",
      "Epoch 94/1000\n",
      "134/134 [==============================] - 47s 354ms/step - loss: 26.4079 - val_loss: 26.3613\n",
      "Epoch 95/1000\n",
      "134/134 [==============================] - 48s 357ms/step - loss: 26.4068 - val_loss: 26.3617\n",
      "Epoch 96/1000\n",
      "134/134 [==============================] - 48s 356ms/step - loss: 26.4072 - val_loss: 26.3597\n",
      "Epoch 97/1000\n",
      "134/134 [==============================] - 47s 350ms/step - loss: 26.4068 - val_loss: 26.3635\n",
      "Epoch 98/1000\n",
      "134/134 [==============================] - 48s 361ms/step - loss: 26.4065 - val_loss: 26.3632\n",
      "Epoch 99/1000\n",
      "134/134 [==============================] - 44s 331ms/step - loss: 26.4068 - val_loss: 26.3595\n",
      "Epoch 100/1000\n",
      "134/134 [==============================] - 45s 339ms/step - loss: 26.4059 - val_loss: 26.3600\n",
      "\n",
      "Epoch 00100: saving model to ./log_weights/Ide_AE_weights.0100.hdf5\n",
      "Epoch 101/1000\n",
      "134/134 [==============================] - 45s 335ms/step - loss: 26.4061 - val_loss: 26.3600\n",
      "Epoch 102/1000\n",
      "134/134 [==============================] - 44s 332ms/step - loss: 26.4058 - val_loss: 26.3579\n",
      "Epoch 103/1000\n",
      "134/134 [==============================] - 46s 346ms/step - loss: 26.4054 - val_loss: 26.3602\n",
      "Epoch 104/1000\n",
      "134/134 [==============================] - 48s 357ms/step - loss: 26.4055 - val_loss: 26.3589\n",
      "Epoch 105/1000\n",
      "134/134 [==============================] - 44s 332ms/step - loss: 26.4051 - val_loss: 26.3603\n",
      "Epoch 106/1000\n",
      "134/134 [==============================] - 46s 347ms/step - loss: 26.4052 - val_loss: 26.3596\n",
      "Epoch 107/1000\n",
      "134/134 [==============================] - 45s 337ms/step - loss: 26.4049 - val_loss: 26.3617\n",
      "Epoch 108/1000\n",
      "134/134 [==============================] - 49s 362ms/step - loss: 26.4049 - val_loss: 26.3580\n",
      "Epoch 109/1000\n",
      "134/134 [==============================] - 45s 338ms/step - loss: 26.4046 - val_loss: 26.3582\n",
      "Epoch 110/1000\n",
      "134/134 [==============================] - 49s 366ms/step - loss: 26.4045 - val_loss: 26.3598\n",
      "Epoch 111/1000\n",
      "134/134 [==============================] - 48s 357ms/step - loss: 26.4046 - val_loss: 26.3580\n",
      "Epoch 112/1000\n",
      "134/134 [==============================] - 47s 354ms/step - loss: 26.4042 - val_loss: 26.3589\n",
      "Epoch 113/1000\n",
      "134/134 [==============================] - 46s 345ms/step - loss: 26.4042 - val_loss: 26.3597\n",
      "Epoch 114/1000\n",
      "134/134 [==============================] - 46s 345ms/step - loss: 26.4040 - val_loss: 26.3597\n",
      "Epoch 115/1000\n",
      "134/134 [==============================] - 48s 359ms/step - loss: 26.4042 - val_loss: 26.3572\n",
      "Epoch 116/1000\n",
      "134/134 [==============================] - 47s 348ms/step - loss: 26.4037 - val_loss: 26.3598\n",
      "Epoch 117/1000\n",
      "134/134 [==============================] - 47s 354ms/step - loss: 26.4036 - val_loss: 26.3584\n",
      "Epoch 118/1000\n",
      "134/134 [==============================] - 47s 349ms/step - loss: 26.4035 - val_loss: 26.3576\n",
      "Epoch 119/1000\n",
      "134/134 [==============================] - 48s 359ms/step - loss: 26.4033 - val_loss: 26.3574\n",
      "Epoch 120/1000\n",
      "134/134 [==============================] - 47s 352ms/step - loss: 26.4034 - val_loss: 26.3574\n",
      "Epoch 121/1000\n",
      "134/134 [==============================] - 49s 364ms/step - loss: 26.4033 - val_loss: 26.3588\n",
      "Epoch 122/1000\n",
      "134/134 [==============================] - 48s 355ms/step - loss: 26.4033 - val_loss: 26.3582\n",
      "Epoch 123/1000\n",
      "134/134 [==============================] - 51s 379ms/step - loss: 26.4032 - val_loss: 26.3583\n",
      "Epoch 124/1000\n",
      "134/134 [==============================] - 49s 366ms/step - loss: 26.4028 - val_loss: 26.3570\n",
      "Epoch 125/1000\n",
      "134/134 [==============================] - 50s 374ms/step - loss: 26.4031 - val_loss: 26.3566\n",
      "Epoch 126/1000\n",
      "134/134 [==============================] - 49s 362ms/step - loss: 26.4027 - val_loss: 26.3567\n",
      "Epoch 127/1000\n",
      "134/134 [==============================] - 49s 364ms/step - loss: 26.4027 - val_loss: 26.3561\n",
      "Epoch 128/1000\n",
      "134/134 [==============================] - 48s 357ms/step - loss: 26.4026 - val_loss: 26.3575\n",
      "Epoch 129/1000\n",
      "134/134 [==============================] - 48s 355ms/step - loss: 26.4026 - val_loss: 26.3574\n",
      "Epoch 130/1000\n",
      "134/134 [==============================] - 47s 352ms/step - loss: 26.4025 - val_loss: 26.3569\n",
      "Epoch 131/1000\n",
      "134/134 [==============================] - 48s 358ms/step - loss: 26.4023 - val_loss: 26.3576\n",
      "Epoch 132/1000\n",
      "134/134 [==============================] - 47s 351ms/step - loss: 26.4025 - val_loss: 26.3572\n",
      "Epoch 133/1000\n",
      "134/134 [==============================] - 48s 356ms/step - loss: 26.4023 - val_loss: 26.3581\n",
      "Epoch 134/1000\n",
      "134/134 [==============================] - 48s 361ms/step - loss: 26.4025 - val_loss: 26.3566\n",
      "Epoch 135/1000\n",
      "134/134 [==============================] - 48s 355ms/step - loss: 26.4021 - val_loss: 26.3575\n",
      "Epoch 136/1000\n",
      "134/134 [==============================] - 48s 357ms/step - loss: 26.4022 - val_loss: 26.3575\n",
      "Epoch 137/1000\n",
      "134/134 [==============================] - 50s 370ms/step - loss: 26.4021 - val_loss: 26.3565\n",
      "Epoch 138/1000\n",
      "134/134 [==============================] - 48s 360ms/step - loss: 26.4020 - val_loss: 26.3571\n",
      "Epoch 139/1000\n",
      "134/134 [==============================] - 49s 363ms/step - loss: 26.4020 - val_loss: 26.3570\n",
      "Epoch 140/1000\n",
      "134/134 [==============================] - 49s 366ms/step - loss: 26.4019 - val_loss: 26.3570\n",
      "Epoch 141/1000\n",
      "134/134 [==============================] - 49s 366ms/step - loss: 26.4019 - val_loss: 26.3566\n",
      "Epoch 142/1000\n",
      "134/134 [==============================] - 49s 366ms/step - loss: 26.4018 - val_loss: 26.3569\n",
      "Epoch 143/1000\n",
      "134/134 [==============================] - 50s 371ms/step - loss: 26.4017 - val_loss: 26.3568\n",
      "Epoch 144/1000\n",
      "134/134 [==============================] - 50s 372ms/step - loss: 26.4017 - val_loss: 26.3561\n",
      "Epoch 145/1000\n",
      "134/134 [==============================] - 50s 376ms/step - loss: 26.4016 - val_loss: 26.3570\n",
      "Epoch 146/1000\n",
      "134/134 [==============================] - 50s 375ms/step - loss: 26.4017 - val_loss: 26.3570\n",
      "Epoch 147/1000\n",
      "134/134 [==============================] - 51s 384ms/step - loss: 26.4016 - val_loss: 26.3563\n",
      "Epoch 148/1000\n",
      "134/134 [==============================] - 51s 377ms/step - loss: 26.4014 - val_loss: 26.3567\n",
      "Epoch 149/1000\n",
      "134/134 [==============================] - 50s 375ms/step - loss: 26.4015 - val_loss: 26.3565\n",
      "Epoch 150/1000\n",
      "134/134 [==============================] - 50s 375ms/step - loss: 26.4013 - val_loss: 26.3567\n",
      "Epoch 151/1000\n",
      "134/134 [==============================] - 49s 368ms/step - loss: 26.4014 - val_loss: 26.3564\n",
      "Epoch 152/1000\n",
      "134/134 [==============================] - 50s 370ms/step - loss: 26.4014 - val_loss: 26.3562\n",
      "Epoch 153/1000\n",
      "134/134 [==============================] - 49s 369ms/step - loss: 26.4013 - val_loss: 26.3560\n",
      "Epoch 154/1000\n",
      "134/134 [==============================] - 48s 358ms/step - loss: 26.4013 - val_loss: 26.3555\n",
      "Epoch 155/1000\n",
      "134/134 [==============================] - 49s 366ms/step - loss: 26.4012 - val_loss: 26.3570\n",
      "Epoch 156/1000\n",
      "134/134 [==============================] - 48s 362ms/step - loss: 26.4012 - val_loss: 26.3560\n",
      "Epoch 157/1000\n",
      "134/134 [==============================] - 49s 368ms/step - loss: 26.4011 - val_loss: 26.3562\n",
      "Epoch 158/1000\n",
      "134/134 [==============================] - 48s 359ms/step - loss: 26.4012 - val_loss: 26.3558\n",
      "Epoch 159/1000\n",
      "134/134 [==============================] - 48s 355ms/step - loss: 26.4010 - val_loss: 26.3561\n",
      "Epoch 160/1000\n",
      "134/134 [==============================] - 49s 364ms/step - loss: 26.4011 - val_loss: 26.3564\n",
      "Epoch 161/1000\n",
      "134/134 [==============================] - 47s 351ms/step - loss: 26.4010 - val_loss: 26.3560\n",
      "Epoch 162/1000\n",
      "134/134 [==============================] - 47s 352ms/step - loss: 26.4010 - val_loss: 26.3559\n",
      "Epoch 163/1000\n",
      "134/134 [==============================] - 48s 356ms/step - loss: 26.4009 - val_loss: 26.3556\n",
      "Epoch 164/1000\n",
      "134/134 [==============================] - 48s 359ms/step - loss: 26.4009 - val_loss: 26.3559\n",
      "Epoch 165/1000\n",
      "134/134 [==============================] - 47s 350ms/step - loss: 26.4009 - val_loss: 26.3558\n",
      "Epoch 166/1000\n",
      "134/134 [==============================] - 46s 346ms/step - loss: 26.4008 - val_loss: 26.3561\n",
      "Epoch 167/1000\n",
      "134/134 [==============================] - 46s 342ms/step - loss: 26.4009 - val_loss: 26.3558\n",
      "Epoch 168/1000\n",
      "134/134 [==============================] - 46s 341ms/step - loss: 26.4008 - val_loss: 26.3559\n",
      "Epoch 169/1000\n",
      "134/134 [==============================] - 46s 341ms/step - loss: 26.4007 - val_loss: 26.3558\n",
      "Epoch 170/1000\n",
      "134/134 [==============================] - 46s 343ms/step - loss: 26.4008 - val_loss: 26.3561\n",
      "Epoch 171/1000\n",
      "134/134 [==============================] - 46s 341ms/step - loss: 26.4007 - val_loss: 26.3553\n",
      "Epoch 172/1000\n",
      "134/134 [==============================] - 46s 342ms/step - loss: 26.4007 - val_loss: 26.3554\n",
      "Epoch 173/1000\n",
      "134/134 [==============================] - 46s 342ms/step - loss: 26.4006 - val_loss: 26.3556\n",
      "Epoch 174/1000\n",
      "134/134 [==============================] - 46s 343ms/step - loss: 26.4006 - val_loss: 26.3556\n",
      "Epoch 175/1000\n",
      "134/134 [==============================] - 46s 342ms/step - loss: 26.4006 - val_loss: 26.3556\n",
      "Epoch 176/1000\n",
      "134/134 [==============================] - 46s 342ms/step - loss: 26.4006 - val_loss: 26.3555\n",
      "Epoch 177/1000\n",
      "134/134 [==============================] - 46s 342ms/step - loss: 26.4006 - val_loss: 26.3555\n",
      "Epoch 178/1000\n",
      "134/134 [==============================] - 46s 346ms/step - loss: 26.4006 - val_loss: 26.3555\n",
      "Epoch 179/1000\n",
      "134/134 [==============================] - 46s 344ms/step - loss: 26.4005 - val_loss: 26.3554\n",
      "Epoch 180/1000\n",
      "134/134 [==============================] - 46s 342ms/step - loss: 26.4004 - val_loss: 26.3553\n",
      "Epoch 181/1000\n",
      "134/134 [==============================] - 46s 344ms/step - loss: 26.4005 - val_loss: 26.3554\n",
      "Epoch 182/1000\n",
      "134/134 [==============================] - 46s 345ms/step - loss: 26.4004 - val_loss: 26.3555\n",
      "Epoch 183/1000\n",
      "134/134 [==============================] - 46s 343ms/step - loss: 26.4004 - val_loss: 26.3558\n",
      "Epoch 184/1000\n",
      "134/134 [==============================] - 46s 344ms/step - loss: 26.4004 - val_loss: 26.3552\n",
      "Epoch 185/1000\n",
      "134/134 [==============================] - 47s 348ms/step - loss: 26.4003 - val_loss: 26.3556\n",
      "Epoch 186/1000\n",
      "134/134 [==============================] - 46s 346ms/step - loss: 26.4004 - val_loss: 26.3553\n",
      "Epoch 187/1000\n",
      "134/134 [==============================] - 46s 346ms/step - loss: 26.4004 - val_loss: 26.3554\n",
      "Epoch 188/1000\n",
      "134/134 [==============================] - 47s 347ms/step - loss: 26.4003 - val_loss: 26.3553\n",
      "Epoch 189/1000\n",
      "134/134 [==============================] - 47s 348ms/step - loss: 26.4003 - val_loss: 26.3553\n",
      "Epoch 190/1000\n",
      "134/134 [==============================] - 46s 347ms/step - loss: 26.4003 - val_loss: 26.3555\n",
      "Epoch 191/1000\n",
      "134/134 [==============================] - 46s 341ms/step - loss: 26.4003 - val_loss: 26.3552\n",
      "Epoch 192/1000\n",
      "134/134 [==============================] - 46s 344ms/step - loss: 26.4003 - val_loss: 26.3551\n",
      "Epoch 193/1000\n",
      "134/134 [==============================] - 47s 352ms/step - loss: 26.4002 - val_loss: 26.3553\n",
      "Epoch 194/1000\n",
      "134/134 [==============================] - 45s 335ms/step - loss: 26.4003 - val_loss: 26.3553\n",
      "Epoch 195/1000\n",
      "134/134 [==============================] - 47s 347ms/step - loss: 26.4002 - val_loss: 26.3554\n",
      "Epoch 196/1000\n",
      "134/134 [==============================] - 49s 362ms/step - loss: 26.4002 - val_loss: 26.3552\n",
      "Epoch 197/1000\n",
      "134/134 [==============================] - 44s 332ms/step - loss: 26.4002 - val_loss: 26.3551\n",
      "Epoch 198/1000\n",
      "134/134 [==============================] - 45s 335ms/step - loss: 26.4002 - val_loss: 26.3551\n",
      "Epoch 199/1000\n",
      "134/134 [==============================] - 47s 351ms/step - loss: 26.4002 - val_loss: 26.3550\n",
      "Epoch 200/1000\n",
      "134/134 [==============================] - 45s 338ms/step - loss: 26.4001 - val_loss: 26.3548\n",
      "\n",
      "Epoch 00200: saving model to ./log_weights/Ide_AE_weights.0200.hdf5\n",
      "Epoch 201/1000\n",
      "134/134 [==============================] - 47s 352ms/step - loss: 26.4001 - val_loss: 26.3549\n",
      "Epoch 202/1000\n",
      "134/134 [==============================] - 44s 329ms/step - loss: 26.4001 - val_loss: 26.3550\n",
      "Epoch 203/1000\n",
      "134/134 [==============================] - 45s 334ms/step - loss: 26.4001 - val_loss: 26.3551\n",
      "Epoch 204/1000\n",
      "134/134 [==============================] - 45s 339ms/step - loss: 26.4001 - val_loss: 26.3551\n",
      "Epoch 205/1000\n",
      "134/134 [==============================] - 47s 349ms/step - loss: 26.4000 - val_loss: 26.3550\n",
      "Epoch 206/1000\n",
      "134/134 [==============================] - 48s 356ms/step - loss: 26.4000 - val_loss: 26.3549\n",
      "Epoch 207/1000\n",
      "134/134 [==============================] - 48s 359ms/step - loss: 26.4000 - val_loss: 26.3551\n",
      "Epoch 208/1000\n",
      "134/134 [==============================] - 48s 360ms/step - loss: 26.4001 - val_loss: 26.3552\n",
      "Epoch 209/1000\n",
      "134/134 [==============================] - 49s 366ms/step - loss: 26.4001 - val_loss: 26.3549\n",
      "Epoch 210/1000\n",
      "134/134 [==============================] - 48s 361ms/step - loss: 26.4000 - val_loss: 26.3549\n",
      "Epoch 211/1000\n",
      "134/134 [==============================] - 47s 348ms/step - loss: 26.4000 - val_loss: 26.3549\n",
      "Epoch 212/1000\n",
      "134/134 [==============================] - 49s 362ms/step - loss: 26.4000 - val_loss: 26.3550\n",
      "Epoch 213/1000\n",
      "134/134 [==============================] - 47s 351ms/step - loss: 26.4000 - val_loss: 26.3550\n",
      "Epoch 214/1000\n",
      "134/134 [==============================] - 45s 338ms/step - loss: 26.3999 - val_loss: 26.3549\n",
      "Epoch 215/1000\n",
      "134/134 [==============================] - 45s 332ms/step - loss: 26.3999 - val_loss: 26.3549\n",
      "Epoch 216/1000\n",
      "134/134 [==============================] - 48s 358ms/step - loss: 26.3999 - val_loss: 26.3552\n",
      "Epoch 217/1000\n",
      "134/134 [==============================] - 45s 333ms/step - loss: 26.3999 - val_loss: 26.3549\n",
      "Epoch 218/1000\n",
      "134/134 [==============================] - 48s 355ms/step - loss: 26.3999 - val_loss: 26.3551\n",
      "Epoch 219/1000\n",
      "134/134 [==============================] - 46s 340ms/step - loss: 26.3999 - val_loss: 26.3548\n",
      "Epoch 220/1000\n",
      "134/134 [==============================] - 44s 332ms/step - loss: 26.3999 - val_loss: 26.3547\n",
      "Epoch 221/1000\n",
      "134/134 [==============================] - 46s 343ms/step - loss: 26.3999 - val_loss: 26.3549\n",
      "Epoch 222/1000\n",
      "134/134 [==============================] - 49s 363ms/step - loss: 26.3999 - val_loss: 26.3548\n",
      "Epoch 223/1000\n",
      "134/134 [==============================] - 49s 362ms/step - loss: 26.3999 - val_loss: 26.3547\n",
      "Epoch 224/1000\n",
      "134/134 [==============================] - 48s 360ms/step - loss: 26.3998 - val_loss: 26.3549\n",
      "Epoch 225/1000\n",
      "134/134 [==============================] - 48s 355ms/step - loss: 26.3999 - val_loss: 26.3548\n",
      "Epoch 226/1000\n",
      "134/134 [==============================] - 47s 354ms/step - loss: 26.3998 - val_loss: 26.3547\n",
      "Epoch 227/1000\n",
      "134/134 [==============================] - 47s 351ms/step - loss: 26.3998 - val_loss: 26.3548\n",
      "Epoch 228/1000\n",
      "134/134 [==============================] - 46s 343ms/step - loss: 26.3998 - val_loss: 26.3547\n",
      "Epoch 229/1000\n",
      "134/134 [==============================] - 48s 355ms/step - loss: 26.3998 - val_loss: 26.3549\n",
      "Epoch 230/1000\n",
      "134/134 [==============================] - 46s 345ms/step - loss: 26.3998 - val_loss: 26.3546\n",
      "Epoch 231/1000\n",
      "134/134 [==============================] - 46s 345ms/step - loss: 26.3998 - val_loss: 26.3548\n",
      "Epoch 232/1000\n",
      "134/134 [==============================] - 46s 347ms/step - loss: 26.3998 - val_loss: 26.3548\n",
      "Epoch 233/1000\n",
      "134/134 [==============================] - 46s 345ms/step - loss: 26.3998 - val_loss: 26.3546\n",
      "Epoch 234/1000\n",
      "134/134 [==============================] - 47s 348ms/step - loss: 26.3998 - val_loss: 26.3547\n",
      "Epoch 235/1000\n",
      "134/134 [==============================] - 49s 362ms/step - loss: 26.3997 - val_loss: 26.3547\n",
      "Epoch 236/1000\n",
      "134/134 [==============================] - 49s 365ms/step - loss: 26.3998 - val_loss: 26.3547\n",
      "Epoch 237/1000\n",
      "134/134 [==============================] - 48s 361ms/step - loss: 26.3997 - val_loss: 26.3546\n",
      "Epoch 238/1000\n",
      "134/134 [==============================] - 49s 363ms/step - loss: 26.3997 - val_loss: 26.3547\n",
      "Epoch 239/1000\n",
      "134/134 [==============================] - 48s 360ms/step - loss: 26.3997 - val_loss: 26.3547\n",
      "Epoch 240/1000\n",
      "134/134 [==============================] - 49s 363ms/step - loss: 26.3997 - val_loss: 26.3547\n",
      "Epoch 241/1000\n",
      "134/134 [==============================] - 49s 362ms/step - loss: 26.3997 - val_loss: 26.3547\n",
      "Epoch 242/1000\n",
      "134/134 [==============================] - 47s 349ms/step - loss: 26.3997 - val_loss: 26.3547\n",
      "Epoch 243/1000\n",
      "134/134 [==============================] - 47s 353ms/step - loss: 26.3996 - val_loss: 26.3545\n",
      "Epoch 244/1000\n",
      "134/134 [==============================] - 45s 336ms/step - loss: 26.3996 - val_loss: 26.3547\n",
      "Epoch 245/1000\n",
      "134/134 [==============================] - 48s 356ms/step - loss: 26.3997 - val_loss: 26.3547\n",
      "Epoch 246/1000\n",
      "134/134 [==============================] - 46s 340ms/step - loss: 26.3997 - val_loss: 26.3546\n",
      "Epoch 247/1000\n",
      "134/134 [==============================] - 45s 338ms/step - loss: 26.3997 - val_loss: 26.3546\n",
      "Epoch 248/1000\n",
      "134/134 [==============================] - 45s 338ms/step - loss: 26.3996 - val_loss: 26.3545\n",
      "Epoch 249/1000\n",
      "134/134 [==============================] - 46s 342ms/step - loss: 26.3996 - val_loss: 26.3546\n",
      "Epoch 250/1000\n",
      "134/134 [==============================] - 47s 351ms/step - loss: 26.3996 - val_loss: 26.3545\n",
      "Epoch 251/1000\n",
      "134/134 [==============================] - 47s 354ms/step - loss: 26.3996 - val_loss: 26.3545\n",
      "Epoch 252/1000\n",
      "134/134 [==============================] - 47s 349ms/step - loss: 26.3996 - val_loss: 26.3545\n",
      "Epoch 253/1000\n",
      "134/134 [==============================] - 47s 351ms/step - loss: 26.3996 - val_loss: 26.3546\n",
      "Epoch 254/1000\n",
      "134/134 [==============================] - 45s 338ms/step - loss: 26.3996 - val_loss: 26.3546\n",
      "Epoch 255/1000\n",
      "134/134 [==============================] - 46s 345ms/step - loss: 26.3996 - val_loss: 26.3546\n",
      "Epoch 256/1000\n",
      "134/134 [==============================] - 47s 354ms/step - loss: 26.3996 - val_loss: 26.3545\n",
      "Epoch 257/1000\n",
      "134/134 [==============================] - 44s 326ms/step - loss: 26.3996 - val_loss: 26.3545\n",
      "Epoch 258/1000\n",
      "134/134 [==============================] - 45s 334ms/step - loss: 26.3996 - val_loss: 26.3546\n",
      "Epoch 259/1000\n",
      "134/134 [==============================] - 44s 331ms/step - loss: 26.3996 - val_loss: 26.3546\n",
      "Epoch 260/1000\n",
      "134/134 [==============================] - 44s 329ms/step - loss: 26.3995 - val_loss: 26.3544\n",
      "Epoch 261/1000\n",
      "134/134 [==============================] - 44s 325ms/step - loss: 26.3996 - val_loss: 26.3545\n",
      "Epoch 262/1000\n",
      "134/134 [==============================] - 44s 329ms/step - loss: 26.3995 - val_loss: 26.3546\n",
      "Epoch 263/1000\n",
      "134/134 [==============================] - 44s 325ms/step - loss: 26.3995 - val_loss: 26.3545\n",
      "Epoch 264/1000\n",
      "134/134 [==============================] - 41s 307ms/step - loss: 26.3995 - val_loss: 26.3546\n",
      "Epoch 265/1000\n",
      "134/134 [==============================] - 42s 312ms/step - loss: 26.3995 - val_loss: 26.3545\n",
      "Epoch 266/1000\n",
      "134/134 [==============================] - 44s 329ms/step - loss: 26.3995 - val_loss: 26.3545\n",
      "Epoch 267/1000\n",
      "134/134 [==============================] - 44s 328ms/step - loss: 26.3995 - val_loss: 26.3544\n",
      "Epoch 268/1000\n",
      "134/134 [==============================] - 43s 319ms/step - loss: 26.3995 - val_loss: 26.3544\n",
      "Epoch 269/1000\n",
      "134/134 [==============================] - 44s 329ms/step - loss: 26.3995 - val_loss: 26.3544\n",
      "Epoch 270/1000\n",
      "134/134 [==============================] - 45s 337ms/step - loss: 26.3995 - val_loss: 26.3545\n",
      "Epoch 271/1000\n",
      "134/134 [==============================] - 42s 315ms/step - loss: 26.3995 - val_loss: 26.3544\n",
      "Epoch 272/1000\n",
      "134/134 [==============================] - 42s 315ms/step - loss: 26.3995 - val_loss: 26.3543\n",
      "Epoch 273/1000\n",
      "134/134 [==============================] - 42s 316ms/step - loss: 26.3995 - val_loss: 26.3543\n",
      "Epoch 274/1000\n",
      "134/134 [==============================] - 42s 316ms/step - loss: 26.3995 - val_loss: 26.3544\n",
      "Epoch 275/1000\n",
      "134/134 [==============================] - 41s 309ms/step - loss: 26.3994 - val_loss: 26.3544\n",
      "Epoch 276/1000\n",
      "134/134 [==============================] - 44s 330ms/step - loss: 26.3995 - val_loss: 26.3545\n",
      "Epoch 277/1000\n",
      "134/134 [==============================] - 43s 318ms/step - loss: 26.3995 - val_loss: 26.3544\n",
      "Epoch 278/1000\n",
      "134/134 [==============================] - 42s 316ms/step - loss: 26.3995 - val_loss: 26.3544\n",
      "Epoch 279/1000\n",
      "134/134 [==============================] - 42s 311ms/step - loss: 26.3994 - val_loss: 26.3544\n",
      "Epoch 280/1000\n",
      "134/134 [==============================] - 44s 330ms/step - loss: 26.3994 - val_loss: 26.3545\n",
      "Epoch 281/1000\n",
      "134/134 [==============================] - 43s 319ms/step - loss: 26.3994 - val_loss: 26.3544\n",
      "Epoch 282/1000\n",
      "134/134 [==============================] - 44s 325ms/step - loss: 26.3994 - val_loss: 26.3545\n",
      "Epoch 283/1000\n",
      "134/134 [==============================] - 44s 326ms/step - loss: 26.3995 - val_loss: 26.3544\n",
      "Epoch 284/1000\n",
      "134/134 [==============================] - 43s 321ms/step - loss: 26.3994 - val_loss: 26.3543\n",
      "Epoch 285/1000\n",
      "134/134 [==============================] - 43s 324ms/step - loss: 26.3994 - val_loss: 26.3544\n",
      "Epoch 286/1000\n",
      "134/134 [==============================] - 43s 324ms/step - loss: 26.3994 - val_loss: 26.3544\n",
      "Epoch 287/1000\n",
      "134/134 [==============================] - 48s 356ms/step - loss: 26.3994 - val_loss: 26.3543\n",
      "Epoch 288/1000\n",
      "134/134 [==============================] - 43s 318ms/step - loss: 26.3994 - val_loss: 26.3543\n",
      "Epoch 289/1000\n",
      "134/134 [==============================] - 44s 332ms/step - loss: 26.3994 - val_loss: 26.3543\n",
      "Epoch 290/1000\n",
      "134/134 [==============================] - 45s 338ms/step - loss: 26.3994 - val_loss: 26.3544\n",
      "Epoch 291/1000\n",
      "134/134 [==============================] - 46s 343ms/step - loss: 26.3994 - val_loss: 26.3544\n",
      "Epoch 292/1000\n",
      "134/134 [==============================] - 44s 330ms/step - loss: 26.3994 - val_loss: 26.3544\n",
      "Epoch 293/1000\n",
      "134/134 [==============================] - 46s 341ms/step - loss: 26.3994 - val_loss: 26.3543\n",
      "Epoch 294/1000\n",
      "134/134 [==============================] - 43s 323ms/step - loss: 26.3993 - val_loss: 26.3543\n",
      "Epoch 295/1000\n",
      "134/134 [==============================] - 41s 308ms/step - loss: 26.3994 - val_loss: 26.3543\n",
      "Epoch 296/1000\n",
      "134/134 [==============================] - 41s 307ms/step - loss: 26.3993 - val_loss: 26.3543\n",
      "Epoch 297/1000\n",
      "134/134 [==============================] - 41s 307ms/step - loss: 26.3994 - val_loss: 26.3543\n",
      "Epoch 298/1000\n",
      "134/134 [==============================] - 41s 306ms/step - loss: 26.3994 - val_loss: 26.3544\n",
      "Epoch 299/1000\n",
      "134/134 [==============================] - 41s 306ms/step - loss: 26.3993 - val_loss: 26.3543\n",
      "Epoch 300/1000\n",
      "134/134 [==============================] - 41s 305ms/step - loss: 26.3994 - val_loss: 26.3543\n",
      "\n",
      "Epoch 00300: saving model to ./log_weights/Ide_AE_weights.0300.hdf5\n",
      "Epoch 301/1000\n",
      "134/134 [==============================] - 41s 306ms/step - loss: 26.3993 - val_loss: 26.3543\n",
      "Epoch 302/1000\n",
      "134/134 [==============================] - 41s 307ms/step - loss: 26.3993 - val_loss: 26.3543\n",
      "Epoch 303/1000\n",
      "134/134 [==============================] - 41s 308ms/step - loss: 26.3993 - val_loss: 26.3543\n",
      "Epoch 304/1000\n",
      "134/134 [==============================] - 41s 307ms/step - loss: 26.3993 - val_loss: 26.3543\n",
      "Epoch 305/1000\n",
      "134/134 [==============================] - 41s 307ms/step - loss: 26.3993 - val_loss: 26.3542\n",
      "Epoch 306/1000\n",
      "134/134 [==============================] - 42s 315ms/step - loss: 26.3993 - val_loss: 26.3543\n",
      "Epoch 307/1000\n",
      "134/134 [==============================] - 42s 315ms/step - loss: 26.3993 - val_loss: 26.3542\n",
      "Epoch 308/1000\n",
      "134/134 [==============================] - 43s 322ms/step - loss: 26.3993 - val_loss: 26.3543\n",
      "Epoch 309/1000\n",
      "134/134 [==============================] - 41s 306ms/step - loss: 26.3993 - val_loss: 26.3542\n",
      "Epoch 310/1000\n",
      "134/134 [==============================] - 42s 313ms/step - loss: 26.3993 - val_loss: 26.3542\n",
      "Epoch 311/1000\n",
      "134/134 [==============================] - 41s 305ms/step - loss: 26.3993 - val_loss: 26.3543\n",
      "Epoch 312/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3993 - val_loss: 26.3543\n",
      "Epoch 313/1000\n",
      "134/134 [==============================] - 39s 292ms/step - loss: 26.3993 - val_loss: 26.3542\n",
      "Epoch 314/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3993 - val_loss: 26.3542\n",
      "Epoch 315/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3993 - val_loss: 26.3543\n",
      "Epoch 316/1000\n",
      "134/134 [==============================] - 40s 296ms/step - loss: 26.3993 - val_loss: 26.3542\n",
      "Epoch 317/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3993 - val_loss: 26.3542\n",
      "Epoch 318/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3992 - val_loss: 26.3542\n",
      "Epoch 319/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3993 - val_loss: 26.3542\n",
      "Epoch 320/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3993 - val_loss: 26.3542\n",
      "Epoch 321/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3993 - val_loss: 26.3543\n",
      "Epoch 322/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3993 - val_loss: 26.3542\n",
      "Epoch 323/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3992 - val_loss: 26.3542\n",
      "Epoch 324/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3992 - val_loss: 26.3541\n",
      "Epoch 325/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3992 - val_loss: 26.3542\n",
      "Epoch 326/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3993 - val_loss: 26.3542\n",
      "Epoch 327/1000\n",
      "134/134 [==============================] - 39s 294ms/step - loss: 26.3992 - val_loss: 26.3541\n",
      "Epoch 328/1000\n",
      "134/134 [==============================] - 40s 297ms/step - loss: 26.3992 - val_loss: 26.3543\n",
      "Epoch 329/1000\n",
      "134/134 [==============================] - 39s 294ms/step - loss: 26.3992 - val_loss: 26.3542\n",
      "Epoch 330/1000\n",
      "134/134 [==============================] - 39s 293ms/step - loss: 26.3992 - val_loss: 26.3542\n",
      "Epoch 331/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3992 - val_loss: 26.3541\n",
      "Epoch 332/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3992 - val_loss: 26.3543\n",
      "Epoch 333/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3992 - val_loss: 26.3542\n",
      "Epoch 334/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3992 - val_loss: 26.3542\n",
      "Epoch 335/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3992 - val_loss: 26.3542\n",
      "Epoch 336/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3992 - val_loss: 26.3542\n",
      "Epoch 337/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3992 - val_loss: 26.3541\n",
      "Epoch 338/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3992 - val_loss: 26.3542\n",
      "Epoch 339/1000\n",
      "134/134 [==============================] - 40s 297ms/step - loss: 26.3992 - val_loss: 26.3542\n",
      "Epoch 340/1000\n",
      "134/134 [==============================] - 39s 292ms/step - loss: 26.3992 - val_loss: 26.3542\n",
      "Epoch 341/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3992 - val_loss: 26.3542\n",
      "Epoch 342/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3992 - val_loss: 26.3542\n",
      "Epoch 343/1000\n",
      "134/134 [==============================] - 39s 293ms/step - loss: 26.3992 - val_loss: 26.3542\n",
      "Epoch 344/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3992 - val_loss: 26.3541\n",
      "Epoch 345/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3992 - val_loss: 26.3542\n",
      "Epoch 346/1000\n",
      "134/134 [==============================] - 38s 287ms/step - loss: 26.3992 - val_loss: 26.3542\n",
      "Epoch 347/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3992 - val_loss: 26.3542\n",
      "Epoch 348/1000\n",
      "134/134 [==============================] - 39s 287ms/step - loss: 26.3992 - val_loss: 26.3542\n",
      "Epoch 349/1000\n",
      "134/134 [==============================] - 38s 287ms/step - loss: 26.3992 - val_loss: 26.3541\n",
      "Epoch 350/1000\n",
      "134/134 [==============================] - 38s 287ms/step - loss: 26.3992 - val_loss: 26.3541\n",
      "Epoch 351/1000\n",
      "134/134 [==============================] - 39s 287ms/step - loss: 26.3992 - val_loss: 26.3541\n",
      "Epoch 352/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3992 - val_loss: 26.3541\n",
      "Epoch 353/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3992 - val_loss: 26.3541\n",
      "Epoch 354/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3992 - val_loss: 26.3541\n",
      "Epoch 355/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3992 - val_loss: 26.3541\n",
      "Epoch 356/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3992 - val_loss: 26.3542\n",
      "Epoch 357/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3992 - val_loss: 26.3541\n",
      "Epoch 358/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3991 - val_loss: 26.3541\n",
      "Epoch 359/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3991 - val_loss: 26.3541\n",
      "Epoch 360/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3992 - val_loss: 26.3541\n",
      "Epoch 361/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3992 - val_loss: 26.3541\n",
      "Epoch 362/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3991 - val_loss: 26.3541\n",
      "Epoch 363/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3991 - val_loss: 26.3541\n",
      "Epoch 364/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3991 - val_loss: 26.3541\n",
      "Epoch 365/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3991 - val_loss: 26.3541\n",
      "Epoch 366/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3991 - val_loss: 26.3541\n",
      "Epoch 367/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3991 - val_loss: 26.3541\n",
      "Epoch 368/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3991 - val_loss: 26.3541\n",
      "Epoch 369/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3991 - val_loss: 26.3541\n",
      "Epoch 370/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3991 - val_loss: 26.3541\n",
      "Epoch 371/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3991 - val_loss: 26.3540\n",
      "Epoch 372/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3991 - val_loss: 26.3541\n",
      "Epoch 373/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3991 - val_loss: 26.3541\n",
      "Epoch 374/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3991 - val_loss: 26.3540\n",
      "Epoch 375/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3991 - val_loss: 26.3541\n",
      "Epoch 376/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3991 - val_loss: 26.3541\n",
      "Epoch 377/1000\n",
      "134/134 [==============================] - 38s 287ms/step - loss: 26.3991 - val_loss: 26.3540\n",
      "Epoch 378/1000\n",
      "134/134 [==============================] - 38s 286ms/step - loss: 26.3991 - val_loss: 26.3541\n",
      "Epoch 379/1000\n",
      "134/134 [==============================] - 38s 287ms/step - loss: 26.3991 - val_loss: 26.3541\n",
      "Epoch 380/1000\n",
      "134/134 [==============================] - 42s 317ms/step - loss: 26.3991 - val_loss: 26.3541\n",
      "Epoch 381/1000\n",
      "134/134 [==============================] - 39s 287ms/step - loss: 26.3991 - val_loss: 26.3541\n",
      "Epoch 382/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3991 - val_loss: 26.3540\n",
      "Epoch 383/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3991 - val_loss: 26.3540\n",
      "Epoch 384/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3991 - val_loss: 26.3541\n",
      "Epoch 385/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3991 - val_loss: 26.3541\n",
      "Epoch 386/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3991 - val_loss: 26.3541\n",
      "Epoch 387/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3991 - val_loss: 26.3541\n",
      "Epoch 388/1000\n",
      "134/134 [==============================] - 40s 301ms/step - loss: 26.3991 - val_loss: 26.3540\n",
      "Epoch 389/1000\n",
      "134/134 [==============================] - 42s 314ms/step - loss: 26.3991 - val_loss: 26.3540\n",
      "Epoch 390/1000\n",
      "134/134 [==============================] - 41s 306ms/step - loss: 26.3991 - val_loss: 26.3540\n",
      "Epoch 391/1000\n",
      "134/134 [==============================] - 43s 317ms/step - loss: 26.3991 - val_loss: 26.3541\n",
      "Epoch 392/1000\n",
      "134/134 [==============================] - 40s 295ms/step - loss: 26.3991 - val_loss: 26.3541\n",
      "Epoch 393/1000\n",
      "134/134 [==============================] - 39s 294ms/step - loss: 26.3991 - val_loss: 26.3541\n",
      "Epoch 394/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3991 - val_loss: 26.3540\n",
      "Epoch 395/1000\n",
      "134/134 [==============================] - 39s 294ms/step - loss: 26.3991 - val_loss: 26.3540\n",
      "Epoch 396/1000\n",
      "134/134 [==============================] - 41s 307ms/step - loss: 26.3991 - val_loss: 26.3541\n",
      "Epoch 397/1000\n",
      "134/134 [==============================] - 40s 298ms/step - loss: 26.3991 - val_loss: 26.3540\n",
      "Epoch 398/1000\n",
      "134/134 [==============================] - 39s 294ms/step - loss: 26.3991 - val_loss: 26.3540\n",
      "Epoch 399/1000\n",
      "134/134 [==============================] - 39s 292ms/step - loss: 26.3991 - val_loss: 26.3541\n",
      "Epoch 400/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3991 - val_loss: 26.3540\n",
      "\n",
      "Epoch 00400: saving model to ./log_weights/Ide_AE_weights.0400.hdf5\n",
      "Epoch 401/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3991 - val_loss: 26.3540\n",
      "Epoch 402/1000\n",
      "134/134 [==============================] - 39s 292ms/step - loss: 26.3991 - val_loss: 26.3540\n",
      "Epoch 403/1000\n",
      "134/134 [==============================] - 40s 295ms/step - loss: 26.3991 - val_loss: 26.3540\n",
      "Epoch 404/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3991 - val_loss: 26.3540\n",
      "Epoch 405/1000\n",
      "134/134 [==============================] - 40s 297ms/step - loss: 26.3991 - val_loss: 26.3540\n",
      "Epoch 406/1000\n",
      "134/134 [==============================] - 40s 295ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 407/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3991 - val_loss: 26.3540\n",
      "Epoch 408/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3991 - val_loss: 26.3540\n",
      "Epoch 409/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3991 - val_loss: 26.3540\n",
      "Epoch 410/1000\n",
      "134/134 [==============================] - 39s 292ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 411/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 412/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3991 - val_loss: 26.3540\n",
      "Epoch 413/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 414/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 415/1000\n",
      "134/134 [==============================] - 39s 292ms/step - loss: 26.3990 - val_loss: 26.3541\n",
      "Epoch 416/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 417/1000\n",
      "134/134 [==============================] - 40s 295ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 418/1000\n",
      "134/134 [==============================] - 39s 292ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 419/1000\n",
      "134/134 [==============================] - 39s 292ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 420/1000\n",
      "134/134 [==============================] - 40s 298ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 421/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 422/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 423/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 424/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 425/1000\n",
      "134/134 [==============================] - 39s 292ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 426/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 427/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 428/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 429/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 430/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 431/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 432/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 433/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 434/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 435/1000\n",
      "134/134 [==============================] - 39s 293ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 436/1000\n",
      "134/134 [==============================] - 39s 293ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 437/1000\n",
      "134/134 [==============================] - 41s 303ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 438/1000\n",
      "134/134 [==============================] - 42s 316ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 439/1000\n",
      "134/134 [==============================] - 42s 312ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 440/1000\n",
      "134/134 [==============================] - 41s 304ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 441/1000\n",
      "134/134 [==============================] - 45s 339ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 442/1000\n",
      "134/134 [==============================] - 46s 341ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 443/1000\n",
      "134/134 [==============================] - 46s 344ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 444/1000\n",
      "134/134 [==============================] - 49s 369ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 445/1000\n",
      "134/134 [==============================] - 51s 380ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 446/1000\n",
      "134/134 [==============================] - 53s 395ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 447/1000\n",
      "134/134 [==============================] - 52s 391ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 448/1000\n",
      "134/134 [==============================] - 54s 400ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 449/1000\n",
      "134/134 [==============================] - 53s 393ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 450/1000\n",
      "134/134 [==============================] - 53s 396ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 451/1000\n",
      "134/134 [==============================] - 58s 432ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 452/1000\n",
      "134/134 [==============================] - 58s 430ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 453/1000\n",
      "134/134 [==============================] - 69s 513ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 454/1000\n",
      "134/134 [==============================] - 85s 632ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 455/1000\n",
      "134/134 [==============================] - 96s 720ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 456/1000\n",
      "134/134 [==============================] - 96s 720ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 457/1000\n",
      "134/134 [==============================] - 94s 700ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 458/1000\n",
      "134/134 [==============================] - 91s 677ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 459/1000\n",
      "134/134 [==============================] - 94s 701ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 460/1000\n",
      "134/134 [==============================] - 88s 656ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 461/1000\n",
      "134/134 [==============================] - 78s 579ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 462/1000\n",
      "134/134 [==============================] - 73s 548ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 463/1000\n",
      "134/134 [==============================] - 61s 453ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 464/1000\n",
      "134/134 [==============================] - 51s 378ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 465/1000\n",
      "134/134 [==============================] - 48s 358ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 466/1000\n",
      "134/134 [==============================] - 46s 345ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 467/1000\n",
      "134/134 [==============================] - 47s 351ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 468/1000\n",
      "134/134 [==============================] - 46s 343ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 469/1000\n",
      "134/134 [==============================] - 45s 334ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 470/1000\n",
      "134/134 [==============================] - 46s 342ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 471/1000\n",
      "134/134 [==============================] - 47s 347ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 472/1000\n",
      "134/134 [==============================] - 45s 336ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 473/1000\n",
      "134/134 [==============================] - 46s 343ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 474/1000\n",
      "134/134 [==============================] - 43s 322ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 475/1000\n",
      "134/134 [==============================] - 42s 314ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 476/1000\n",
      "134/134 [==============================] - 42s 314ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 477/1000\n",
      "134/134 [==============================] - 42s 315ms/step - loss: 26.3990 - val_loss: 26.3540\n",
      "Epoch 478/1000\n",
      "134/134 [==============================] - 42s 315ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 479/1000\n",
      "134/134 [==============================] - 42s 315ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 480/1000\n",
      "134/134 [==============================] - 42s 315ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 481/1000\n",
      "134/134 [==============================] - 42s 315ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 482/1000\n",
      "134/134 [==============================] - 43s 319ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 483/1000\n",
      "134/134 [==============================] - 42s 314ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 484/1000\n",
      "134/134 [==============================] - 43s 321ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 485/1000\n",
      "134/134 [==============================] - 42s 314ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 486/1000\n",
      "134/134 [==============================] - 42s 313ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 487/1000\n",
      "134/134 [==============================] - 42s 315ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 488/1000\n",
      "134/134 [==============================] - 42s 316ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 489/1000\n",
      "134/134 [==============================] - 43s 320ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 490/1000\n",
      "134/134 [==============================] - 43s 320ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 491/1000\n",
      "134/134 [==============================] - 42s 316ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 492/1000\n",
      "134/134 [==============================] - 42s 316ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 493/1000\n",
      "134/134 [==============================] - 42s 316ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 494/1000\n",
      "134/134 [==============================] - 42s 315ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 495/1000\n",
      "134/134 [==============================] - 42s 315ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 496/1000\n",
      "134/134 [==============================] - 42s 315ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 497/1000\n",
      "134/134 [==============================] - 42s 315ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 498/1000\n",
      "134/134 [==============================] - 42s 317ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 499/1000\n",
      "134/134 [==============================] - 43s 317ms/step - loss: 26.3990 - val_loss: 26.3539\n",
      "Epoch 500/1000\n",
      "134/134 [==============================] - 43s 318ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "\n",
      "Epoch 00500: saving model to ./log_weights/Ide_AE_weights.0500.hdf5\n",
      "Epoch 501/1000\n",
      "134/134 [==============================] - 44s 327ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 502/1000\n",
      "134/134 [==============================] - 43s 318ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 503/1000\n",
      "134/134 [==============================] - 43s 318ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 504/1000\n",
      "134/134 [==============================] - 43s 320ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 505/1000\n",
      "134/134 [==============================] - 43s 319ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 506/1000\n",
      "134/134 [==============================] - 43s 320ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 507/1000\n",
      "134/134 [==============================] - 43s 319ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 508/1000\n",
      "134/134 [==============================] - 43s 319ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 509/1000\n",
      "134/134 [==============================] - 43s 319ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 510/1000\n",
      "134/134 [==============================] - 43s 319ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 511/1000\n",
      "134/134 [==============================] - 43s 318ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 512/1000\n",
      "134/134 [==============================] - 42s 316ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 513/1000\n",
      "134/134 [==============================] - 42s 317ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 514/1000\n",
      "134/134 [==============================] - 42s 317ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 515/1000\n",
      "134/134 [==============================] - 43s 318ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 516/1000\n",
      "134/134 [==============================] - 43s 318ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 517/1000\n",
      "134/134 [==============================] - 43s 318ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 518/1000\n",
      "134/134 [==============================] - 43s 320ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 519/1000\n",
      "134/134 [==============================] - 43s 322ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 520/1000\n",
      "134/134 [==============================] - 43s 323ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 521/1000\n",
      "134/134 [==============================] - 42s 313ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 522/1000\n",
      "134/134 [==============================] - 42s 314ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 523/1000\n",
      "134/134 [==============================] - 42s 315ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 524/1000\n",
      "134/134 [==============================] - 42s 317ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 525/1000\n",
      "134/134 [==============================] - 42s 315ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 526/1000\n",
      "134/134 [==============================] - 42s 315ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 527/1000\n",
      "134/134 [==============================] - 42s 314ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 528/1000\n",
      "134/134 [==============================] - 42s 315ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 529/1000\n",
      "134/134 [==============================] - 42s 312ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 530/1000\n",
      "134/134 [==============================] - 42s 312ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 531/1000\n",
      "134/134 [==============================] - 42s 315ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 532/1000\n",
      "134/134 [==============================] - 45s 332ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 533/1000\n",
      "134/134 [==============================] - 43s 320ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 534/1000\n",
      "134/134 [==============================] - 42s 310ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 535/1000\n",
      "134/134 [==============================] - 43s 320ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 536/1000\n",
      "134/134 [==============================] - 39s 293ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 537/1000\n",
      "134/134 [==============================] - 39s 293ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 538/1000\n",
      "134/134 [==============================] - 39s 293ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 539/1000\n",
      "134/134 [==============================] - 39s 292ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 540/1000\n",
      "134/134 [==============================] - 39s 292ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 541/1000\n",
      "134/134 [==============================] - 39s 293ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 542/1000\n",
      "134/134 [==============================] - 40s 298ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 543/1000\n",
      "134/134 [==============================] - 39s 295ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 544/1000\n",
      "134/134 [==============================] - 40s 295ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 545/1000\n",
      "134/134 [==============================] - 39s 295ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 546/1000\n",
      "134/134 [==============================] - 40s 295ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 547/1000\n",
      "134/134 [==============================] - 43s 324ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 548/1000\n",
      "134/134 [==============================] - 41s 303ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 549/1000\n",
      "134/134 [==============================] - 40s 298ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 550/1000\n",
      "134/134 [==============================] - 40s 297ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 551/1000\n",
      "134/134 [==============================] - 40s 297ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 552/1000\n",
      "134/134 [==============================] - 40s 296ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 553/1000\n",
      "134/134 [==============================] - 40s 295ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 554/1000\n",
      "134/134 [==============================] - 40s 295ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 555/1000\n",
      "134/134 [==============================] - 41s 308ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 556/1000\n",
      "134/134 [==============================] - 42s 314ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 557/1000\n",
      "134/134 [==============================] - 42s 315ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 558/1000\n",
      "134/134 [==============================] - 41s 304ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 559/1000\n",
      "134/134 [==============================] - 40s 295ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 560/1000\n",
      "134/134 [==============================] - 40s 296ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 561/1000\n",
      "134/134 [==============================] - 40s 298ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 562/1000\n",
      "134/134 [==============================] - 40s 298ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 563/1000\n",
      "134/134 [==============================] - 41s 305ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 564/1000\n",
      "134/134 [==============================] - 40s 300ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 565/1000\n",
      "134/134 [==============================] - 40s 296ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 566/1000\n",
      "134/134 [==============================] - 41s 303ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 567/1000\n",
      "134/134 [==============================] - 42s 316ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 568/1000\n",
      "134/134 [==============================] - 41s 307ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 569/1000\n",
      "134/134 [==============================] - 42s 317ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 570/1000\n",
      "134/134 [==============================] - 52s 385ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 571/1000\n",
      "134/134 [==============================] - 52s 387ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 572/1000\n",
      "134/134 [==============================] - 49s 363ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 573/1000\n",
      "134/134 [==============================] - 49s 368ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 574/1000\n",
      "134/134 [==============================] - 51s 379ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 575/1000\n",
      "134/134 [==============================] - 49s 367ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 576/1000\n",
      "134/134 [==============================] - 47s 353ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 577/1000\n",
      "134/134 [==============================] - 43s 321ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 578/1000\n",
      "134/134 [==============================] - 42s 316ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 579/1000\n",
      "134/134 [==============================] - 43s 318ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 580/1000\n",
      "134/134 [==============================] - 42s 317ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 581/1000\n",
      "134/134 [==============================] - 43s 317ms/step - loss: 26.3989 - val_loss: 26.3539\n",
      "Epoch 582/1000\n",
      "134/134 [==============================] - 43s 317ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 583/1000\n",
      "134/134 [==============================] - 43s 317ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 584/1000\n",
      "134/134 [==============================] - 43s 318ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 585/1000\n",
      "134/134 [==============================] - 42s 317ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 586/1000\n",
      "134/134 [==============================] - 43s 317ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 587/1000\n",
      "134/134 [==============================] - 42s 317ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 588/1000\n",
      "134/134 [==============================] - 42s 315ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 589/1000\n",
      "134/134 [==============================] - 42s 313ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 590/1000\n",
      "134/134 [==============================] - 42s 310ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 591/1000\n",
      "134/134 [==============================] - 42s 310ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 592/1000\n",
      "134/134 [==============================] - 41s 308ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 593/1000\n",
      "134/134 [==============================] - 41s 309ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 594/1000\n",
      "134/134 [==============================] - 41s 308ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 595/1000\n",
      "134/134 [==============================] - 41s 308ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 596/1000\n",
      "134/134 [==============================] - 41s 307ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 597/1000\n",
      "134/134 [==============================] - 41s 308ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 598/1000\n",
      "134/134 [==============================] - 41s 308ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 599/1000\n",
      "134/134 [==============================] - 42s 312ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 600/1000\n",
      "134/134 [==============================] - 41s 306ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "\n",
      "Epoch 00600: saving model to ./log_weights/Ide_AE_weights.0600.hdf5\n",
      "Epoch 601/1000\n",
      "134/134 [==============================] - 41s 305ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 602/1000\n",
      "134/134 [==============================] - 41s 307ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 603/1000\n",
      "134/134 [==============================] - 41s 304ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 604/1000\n",
      "134/134 [==============================] - 41s 304ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 605/1000\n",
      "134/134 [==============================] - 41s 303ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 606/1000\n",
      "134/134 [==============================] - 41s 303ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 607/1000\n",
      "134/134 [==============================] - 41s 304ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 608/1000\n",
      "134/134 [==============================] - 41s 304ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 609/1000\n",
      "134/134 [==============================] - 41s 305ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 610/1000\n",
      "134/134 [==============================] - 41s 306ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 611/1000\n",
      "134/134 [==============================] - 41s 308ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 612/1000\n",
      "134/134 [==============================] - 44s 325ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 613/1000\n",
      "134/134 [==============================] - 41s 307ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 614/1000\n",
      "134/134 [==============================] - 41s 309ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 615/1000\n",
      "134/134 [==============================] - 41s 308ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 616/1000\n",
      "134/134 [==============================] - 43s 321ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 617/1000\n",
      "134/134 [==============================] - 62s 463ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 618/1000\n",
      "134/134 [==============================] - 222s 2s/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 619/1000\n",
      "134/134 [==============================] - 212s 2s/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 620/1000\n",
      "134/134 [==============================] - 70s 522ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 621/1000\n",
      "134/134 [==============================] - 45s 334ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 622/1000\n",
      "134/134 [==============================] - 45s 334ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 623/1000\n",
      "134/134 [==============================] - 45s 333ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 624/1000\n",
      "134/134 [==============================] - 45s 333ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 625/1000\n",
      "134/134 [==============================] - 45s 334ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 626/1000\n",
      "134/134 [==============================] - 45s 333ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 627/1000\n",
      "134/134 [==============================] - 45s 334ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 628/1000\n",
      "134/134 [==============================] - 45s 333ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 629/1000\n",
      "134/134 [==============================] - 45s 334ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 630/1000\n",
      "134/134 [==============================] - 45s 334ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 631/1000\n",
      "134/134 [==============================] - 45s 335ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 632/1000\n",
      "134/134 [==============================] - 45s 334ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 633/1000\n",
      "134/134 [==============================] - 45s 334ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 634/1000\n",
      "134/134 [==============================] - 45s 334ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 635/1000\n",
      "134/134 [==============================] - 45s 334ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 636/1000\n",
      "134/134 [==============================] - 45s 334ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 637/1000\n",
      "134/134 [==============================] - 46s 343ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 638/1000\n",
      "134/134 [==============================] - 46s 346ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 639/1000\n",
      "134/134 [==============================] - 45s 333ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 640/1000\n",
      "134/134 [==============================] - 45s 334ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 641/1000\n",
      "134/134 [==============================] - 44s 331ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 642/1000\n",
      "134/134 [==============================] - 45s 333ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 643/1000\n",
      "134/134 [==============================] - 45s 332ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 644/1000\n",
      "134/134 [==============================] - 45s 332ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 645/1000\n",
      "134/134 [==============================] - 44s 330ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 646/1000\n",
      "134/134 [==============================] - 44s 329ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 647/1000\n",
      "134/134 [==============================] - 44s 327ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 648/1000\n",
      "134/134 [==============================] - 44s 326ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 649/1000\n",
      "134/134 [==============================] - 44s 326ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 650/1000\n",
      "134/134 [==============================] - 44s 329ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 651/1000\n",
      "134/134 [==============================] - 44s 330ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 652/1000\n",
      "134/134 [==============================] - 44s 325ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 653/1000\n",
      "134/134 [==============================] - 45s 335ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 654/1000\n",
      "134/134 [==============================] - 49s 362ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 655/1000\n",
      "134/134 [==============================] - 47s 352ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 656/1000\n",
      "134/134 [==============================] - 43s 323ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 657/1000\n",
      "134/134 [==============================] - 43s 323ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 658/1000\n",
      "134/134 [==============================] - 43s 324ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 659/1000\n",
      "134/134 [==============================] - 45s 337ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 660/1000\n",
      "134/134 [==============================] - 43s 323ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 661/1000\n",
      "134/134 [==============================] - 45s 337ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 662/1000\n",
      "134/134 [==============================] - 47s 354ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 663/1000\n",
      "134/134 [==============================] - 59s 437ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 664/1000\n",
      "134/134 [==============================] - 57s 423ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 665/1000\n",
      "134/134 [==============================] - 50s 374ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 666/1000\n",
      "134/134 [==============================] - 54s 401ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 667/1000\n",
      "134/134 [==============================] - 47s 351ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 668/1000\n",
      "134/134 [==============================] - 51s 380ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 669/1000\n",
      "134/134 [==============================] - 52s 386ms/step - loss: 26.3989 - val_loss: 26.3538\n",
      "Epoch 670/1000\n",
      "134/134 [==============================] - 51s 379ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 671/1000\n",
      "134/134 [==============================] - 50s 376ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 672/1000\n",
      "134/134 [==============================] - 49s 367ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 673/1000\n",
      "134/134 [==============================] - 49s 364ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 674/1000\n",
      "134/134 [==============================] - 52s 389ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 675/1000\n",
      "134/134 [==============================] - 50s 375ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 676/1000\n",
      "134/134 [==============================] - 57s 429ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 677/1000\n",
      "134/134 [==============================] - 69s 513ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 678/1000\n",
      "134/134 [==============================] - 89s 663ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 679/1000\n",
      "134/134 [==============================] - 78s 584ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 680/1000\n",
      "134/134 [==============================] - 77s 574ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 681/1000\n",
      "134/134 [==============================] - 53s 393ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 682/1000\n",
      "134/134 [==============================] - 48s 359ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 683/1000\n",
      "134/134 [==============================] - 46s 347ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 684/1000\n",
      "134/134 [==============================] - 46s 340ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 685/1000\n",
      "134/134 [==============================] - 45s 338ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 686/1000\n",
      "134/134 [==============================] - 45s 333ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 687/1000\n",
      "134/134 [==============================] - 45s 333ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 688/1000\n",
      "134/134 [==============================] - 44s 331ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 689/1000\n",
      "134/134 [==============================] - 44s 331ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 690/1000\n",
      "134/134 [==============================] - 44s 330ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 691/1000\n",
      "134/134 [==============================] - 47s 352ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 692/1000\n",
      "134/134 [==============================] - 48s 358ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 693/1000\n",
      "134/134 [==============================] - 47s 354ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 694/1000\n",
      "134/134 [==============================] - 44s 329ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 695/1000\n",
      "134/134 [==============================] - 44s 326ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 696/1000\n",
      "134/134 [==============================] - 45s 338ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 697/1000\n",
      "134/134 [==============================] - 45s 338ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 698/1000\n",
      "134/134 [==============================] - 44s 329ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 699/1000\n",
      "134/134 [==============================] - 43s 319ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 700/1000\n",
      "134/134 [==============================] - 47s 352ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "\n",
      "Epoch 00700: saving model to ./log_weights/Ide_AE_weights.0700.hdf5\n",
      "Epoch 701/1000\n",
      "134/134 [==============================] - 46s 345ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 702/1000\n",
      "134/134 [==============================] - 41s 305ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 703/1000\n",
      "134/134 [==============================] - 41s 305ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 704/1000\n",
      "134/134 [==============================] - 41s 305ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 705/1000\n",
      "134/134 [==============================] - 41s 309ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 706/1000\n",
      "134/134 [==============================] - 42s 311ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 707/1000\n",
      "134/134 [==============================] - 42s 312ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 708/1000\n",
      "134/134 [==============================] - 42s 312ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 709/1000\n",
      "134/134 [==============================] - 42s 310ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 710/1000\n",
      "134/134 [==============================] - 42s 310ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 711/1000\n",
      "134/134 [==============================] - 42s 310ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 712/1000\n",
      "134/134 [==============================] - 42s 311ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 713/1000\n",
      "134/134 [==============================] - 42s 310ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 714/1000\n",
      "134/134 [==============================] - 41s 309ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 715/1000\n",
      "134/134 [==============================] - 41s 308ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 716/1000\n",
      "134/134 [==============================] - 41s 308ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 717/1000\n",
      "134/134 [==============================] - 41s 308ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 718/1000\n",
      "134/134 [==============================] - 41s 308ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 719/1000\n",
      "134/134 [==============================] - 41s 310ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 720/1000\n",
      "134/134 [==============================] - 41s 310ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 721/1000\n",
      "134/134 [==============================] - 41s 309ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 722/1000\n",
      "134/134 [==============================] - 41s 309ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 723/1000\n",
      "134/134 [==============================] - 41s 308ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 724/1000\n",
      "134/134 [==============================] - 41s 307ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 725/1000\n",
      "134/134 [==============================] - 41s 307ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 726/1000\n",
      "134/134 [==============================] - 41s 305ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 727/1000\n",
      "134/134 [==============================] - 41s 303ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 728/1000\n",
      "134/134 [==============================] - 40s 299ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 729/1000\n",
      "134/134 [==============================] - 40s 297ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 730/1000\n",
      "134/134 [==============================] - 40s 297ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 731/1000\n",
      "134/134 [==============================] - 40s 300ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 732/1000\n",
      "134/134 [==============================] - 40s 299ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 733/1000\n",
      "134/134 [==============================] - 40s 296ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 734/1000\n",
      "134/134 [==============================] - 40s 297ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 735/1000\n",
      "134/134 [==============================] - 40s 298ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 736/1000\n",
      "134/134 [==============================] - 40s 297ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 737/1000\n",
      "134/134 [==============================] - 40s 296ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 738/1000\n",
      "134/134 [==============================] - 40s 295ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 739/1000\n",
      "134/134 [==============================] - 40s 295ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 740/1000\n",
      "134/134 [==============================] - 39s 293ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 741/1000\n",
      "134/134 [==============================] - 39s 293ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 742/1000\n",
      "134/134 [==============================] - 39s 293ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 743/1000\n",
      "134/134 [==============================] - 39s 294ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 744/1000\n",
      "134/134 [==============================] - 40s 295ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 745/1000\n",
      "134/134 [==============================] - 40s 296ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 746/1000\n",
      "134/134 [==============================] - 40s 297ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 747/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 748/1000\n",
      "134/134 [==============================] - 40s 296ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 749/1000\n",
      "134/134 [==============================] - 40s 302ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 750/1000\n",
      "134/134 [==============================] - 41s 307ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 751/1000\n",
      "134/134 [==============================] - 39s 293ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 752/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 753/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 754/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 755/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 756/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 757/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 758/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 759/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 760/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 761/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 762/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 763/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 764/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 765/1000\n",
      "134/134 [==============================] - 39s 293ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 766/1000\n",
      "134/134 [==============================] - 39s 294ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 767/1000\n",
      "134/134 [==============================] - 39s 292ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 768/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 769/1000\n",
      "134/134 [==============================] - 39s 292ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 770/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 771/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 772/1000\n",
      "134/134 [==============================] - 39s 292ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 773/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 774/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 775/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 776/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 777/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 778/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 779/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 780/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 781/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 782/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 783/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 784/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 785/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 786/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 787/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 788/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 789/1000\n",
      "134/134 [==============================] - 42s 311ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 790/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 791/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 792/1000\n",
      "134/134 [==============================] - 39s 292ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 793/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 794/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 795/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 796/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 797/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 798/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 799/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 800/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "\n",
      "Epoch 00800: saving model to ./log_weights/Ide_AE_weights.0800.hdf5\n",
      "Epoch 801/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 802/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 803/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 804/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 805/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 806/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 807/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 808/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 809/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 810/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 811/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 812/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 813/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 814/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 815/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 816/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 817/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 818/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 819/1000\n",
      "134/134 [==============================] - 39s 293ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 820/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 821/1000\n",
      "134/134 [==============================] - 39s 292ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 822/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 823/1000\n",
      "134/134 [==============================] - 42s 315ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 824/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 825/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 826/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 827/1000\n",
      "134/134 [==============================] - 39s 287ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 828/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 829/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 830/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 831/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 832/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 833/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 834/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 835/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 836/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 837/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 838/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 839/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 840/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 841/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 842/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 843/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 844/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 845/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 846/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 847/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 848/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 849/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 850/1000\n",
      "134/134 [==============================] - 40s 296ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 851/1000\n",
      "134/134 [==============================] - 39s 294ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 852/1000\n",
      "134/134 [==============================] - 38s 287ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 853/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 854/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 855/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 856/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 857/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 858/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 859/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 860/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 861/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 862/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 863/1000\n",
      "134/134 [==============================] - 42s 314ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 864/1000\n",
      "134/134 [==============================] - 45s 332ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 865/1000\n",
      "134/134 [==============================] - 42s 310ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 866/1000\n",
      "134/134 [==============================] - 39s 292ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 867/1000\n",
      "134/134 [==============================] - 39s 292ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 868/1000\n",
      "134/134 [==============================] - 39s 293ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 869/1000\n",
      "134/134 [==============================] - 39s 292ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 870/1000\n",
      "134/134 [==============================] - 39s 292ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 871/1000\n",
      "134/134 [==============================] - 40s 299ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 872/1000\n",
      "134/134 [==============================] - 39s 292ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 873/1000\n",
      "134/134 [==============================] - 39s 292ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 874/1000\n",
      "134/134 [==============================] - 39s 292ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 875/1000\n",
      "134/134 [==============================] - 39s 292ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 876/1000\n",
      "134/134 [==============================] - 39s 293ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 877/1000\n",
      "134/134 [==============================] - 39s 294ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 878/1000\n",
      "134/134 [==============================] - 39s 293ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 879/1000\n",
      "134/134 [==============================] - 39s 294ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 880/1000\n",
      "134/134 [==============================] - 39s 287ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 881/1000\n",
      "134/134 [==============================] - 38s 287ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 882/1000\n",
      "134/134 [==============================] - 38s 287ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 883/1000\n",
      "134/134 [==============================] - 38s 287ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 884/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 885/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 886/1000\n",
      "134/134 [==============================] - 38s 287ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 887/1000\n",
      "134/134 [==============================] - 38s 287ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 888/1000\n",
      "134/134 [==============================] - 38s 287ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 889/1000\n",
      "134/134 [==============================] - 38s 287ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 890/1000\n",
      "134/134 [==============================] - 38s 287ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 891/1000\n",
      "134/134 [==============================] - 38s 286ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 892/1000\n",
      "134/134 [==============================] - 38s 287ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 893/1000\n",
      "134/134 [==============================] - 39s 287ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 894/1000\n",
      "134/134 [==============================] - 38s 286ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 895/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 896/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 897/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 898/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 899/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 900/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "\n",
      "Epoch 00900: saving model to ./log_weights/Ide_AE_weights.0900.hdf5\n",
      "Epoch 901/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 902/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 903/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 904/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 905/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 906/1000\n",
      "134/134 [==============================] - 39s 292ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 907/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 908/1000\n",
      "134/134 [==============================] - 40s 298ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 909/1000\n",
      "134/134 [==============================] - 40s 300ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 910/1000\n",
      "134/134 [==============================] - 39s 293ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 911/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 912/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 913/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 914/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 915/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 916/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 917/1000\n",
      "134/134 [==============================] - 38s 287ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 918/1000\n",
      "134/134 [==============================] - 38s 287ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 919/1000\n",
      "134/134 [==============================] - 38s 286ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 920/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 921/1000\n",
      "134/134 [==============================] - 38s 287ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 922/1000\n",
      "134/134 [==============================] - 38s 287ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 923/1000\n",
      "134/134 [==============================] - 38s 287ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 924/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 925/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 926/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 927/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 928/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 929/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 930/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 931/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 932/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 933/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 934/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 935/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 936/1000\n",
      "134/134 [==============================] - 39s 290ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 937/1000\n",
      "134/134 [==============================] - 40s 298ms/step - loss: 26.3988 - val_loss: 26.3537\n",
      "Epoch 938/1000\n",
      "134/134 [==============================] - 40s 300ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 939/1000\n",
      "134/134 [==============================] - 39s 292ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 940/1000\n",
      "134/134 [==============================] - 39s 289ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 941/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 942/1000\n",
      "134/134 [==============================] - 38s 287ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 943/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 944/1000\n",
      "134/134 [==============================] - 38s 287ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 945/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 946/1000\n",
      "134/134 [==============================] - 38s 287ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 947/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 948/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 949/1000\n",
      "134/134 [==============================] - 38s 286ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 950/1000\n",
      "134/134 [==============================] - 38s 287ms/step - loss: 26.3988 - val_loss: 26.3537\n",
      "Epoch 951/1000\n",
      "134/134 [==============================] - 38s 286ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 952/1000\n",
      "134/134 [==============================] - 38s 287ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 953/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 954/1000\n",
      "134/134 [==============================] - 38s 287ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 955/1000\n",
      "134/134 [==============================] - 39s 288ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 956/1000\n",
      "134/134 [==============================] - 40s 296ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 957/1000\n",
      "134/134 [==============================] - 39s 294ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 958/1000\n",
      "134/134 [==============================] - 40s 297ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 959/1000\n",
      "134/134 [==============================] - 40s 301ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 960/1000\n",
      "134/134 [==============================] - 39s 291ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 961/1000\n",
      "134/134 [==============================] - 40s 297ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 962/1000\n",
      "134/134 [==============================] - 41s 304ms/step - loss: 26.3988 - val_loss: 26.3537\n",
      "Epoch 963/1000\n",
      "134/134 [==============================] - 44s 331ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 964/1000\n",
      "134/134 [==============================] - 47s 348ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 965/1000\n",
      "134/134 [==============================] - 48s 361ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 966/1000\n",
      "134/134 [==============================] - 49s 369ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 967/1000\n",
      "134/134 [==============================] - 51s 381ms/step - loss: 26.3988 - val_loss: 26.3537\n",
      "Epoch 968/1000\n",
      "134/134 [==============================] - 54s 402ms/step - loss: 26.3988 - val_loss: 26.3537\n",
      "Epoch 969/1000\n",
      "134/134 [==============================] - 52s 388ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 970/1000\n",
      "134/134 [==============================] - 51s 384ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 971/1000\n",
      "134/134 [==============================] - 49s 367ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 972/1000\n",
      "134/134 [==============================] - 51s 377ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 973/1000\n",
      "134/134 [==============================] - 53s 397ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 974/1000\n",
      "134/134 [==============================] - 57s 426ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 975/1000\n",
      "134/134 [==============================] - 70s 526ms/step - loss: 26.3988 - val_loss: 26.3537\n",
      "Epoch 976/1000\n",
      "134/134 [==============================] - 77s 571ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 977/1000\n",
      "134/134 [==============================] - 89s 662ms/step - loss: 26.3988 - val_loss: 26.3537\n",
      "Epoch 978/1000\n",
      "134/134 [==============================] - 70s 523ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 979/1000\n",
      "134/134 [==============================] - 95s 709ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 980/1000\n",
      "134/134 [==============================] - 92s 686ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 981/1000\n",
      "134/134 [==============================] - 132s 988ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 982/1000\n",
      "134/134 [==============================] - 90s 669ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 983/1000\n",
      "134/134 [==============================] - 84s 630ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 984/1000\n",
      "134/134 [==============================] - 82s 613ms/step - loss: 26.3988 - val_loss: 26.3537\n",
      "Epoch 985/1000\n",
      "134/134 [==============================] - 71s 532ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 986/1000\n",
      "134/134 [==============================] - 56s 421ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 987/1000\n",
      "134/134 [==============================] - 50s 369ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 988/1000\n",
      "134/134 [==============================] - 49s 363ms/step - loss: 26.3988 - val_loss: 26.3537\n",
      "Epoch 989/1000\n",
      "134/134 [==============================] - 48s 357ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 990/1000\n",
      "134/134 [==============================] - 47s 349ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 991/1000\n",
      "134/134 [==============================] - 46s 344ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 992/1000\n",
      "134/134 [==============================] - 46s 340ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 993/1000\n",
      "134/134 [==============================] - 47s 349ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 994/1000\n",
      "134/134 [==============================] - 46s 341ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 995/1000\n",
      "134/134 [==============================] - 48s 361ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 996/1000\n",
      "134/134 [==============================] - 50s 373ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 997/1000\n",
      "134/134 [==============================] - 49s 364ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 998/1000\n",
      "134/134 [==============================] - 52s 388ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 999/1000\n",
      "134/134 [==============================] - 53s 399ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "Epoch 1000/1000\n",
      "134/134 [==============================] - 60s 444ms/step - loss: 26.3988 - val_loss: 26.3538\n",
      "\n",
      "Epoch 01000: saving model to ./log_weights/Ide_AE_weights.1000.hdf5\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint=ModelCheckpoint('./log_weights/Ide_AE_weights.{epoch:04d}.hdf5',period=100,save_weights_only=True,verbose=1)\n",
    "#print_weights = LambdaCallback(on_epoch_end=lambda batch, logs: print(Ide_AE.layers[1].get_weights()))\n",
    "\n",
    "Ide_AE_history = Ide_AE.fit(x_train, x_train,\\\n",
    "                            epochs=epochs_number,\\\n",
    "                            batch_size=batch_size_value,\\\n",
    "                            shuffle=True,\\\n",
    "                            validation_data=(x_validate,x_validate),\\\n",
    "                            callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEJCAYAAACDscAcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAr6klEQVR4nO3de1zUdaL/8dcMIwgMAjNELphbmO05XpAKr2dTE8xK2zxsl19l+7DcLlK66Ekba3fbPW1FW17KS3paj67m2dpNpMs5Ww8V0bOZG+YlL5upmZloCIM2yCAw8/39gcyRkIFRYIR5Px8PHjHfmfl+P5/5Ju/5fD7f7+djMgzDQEREpIXMwS6AiIh0LAoOEREJiIJDREQCouAQEZGAKDhERCQgCg4REQmIJdgFaA/FxcUX/N6EhARKS0tbsTSXtlCrL6jOoUJ1DkxSUlKTz6nFISIiAVFwiIhIQBQcIiISkJAY4xCR9mEYBlVVVXi9XkwmU7CL08C3337LmTNngl2MdtVcnQ3DwGw207Vr14DOl4JDRFpNVVUVXbp0wWK59P60WCwWwsLCgl2MdtWSOtfW1lJVVUVkZGSL96uuqibk5UUyaFAiXbt2YdCgRPLyWv6hioQqr9d7SYaGNM1iseD1egN7TxuVpUPLy4tk5sxY3O66XD161MLMmbEAZGW5g1k0kUvapdY9JS0T6HlTi+M8cnNjfKFRz+02k5sbE6QSiYhcOhQc51FcfP4+waa2i0jwOZ1ORo8ezejRo0lLS+P666/3Pa6urvb73p07d/KrX/2q2WP85Cc/aZWybt68mZ/97Getsq9gUFfVeSQleTh6tPFHk5TkCUJpRDqvvLxIcnNjKC4OIynJg8PhuuDuYJvNxtq1awGYPXs20dHRPProo77na2trm3zvgAEDGDBgQLPHePfddy+obJ2NguM8HA5XgzEOgMhILw6HK4ilEulc2mMsMScnh4iICPbs2cOgQYO47bbb+PWvf82ZM2fo2rUrc+bM4eqrr2bz5s0sXryYFStWMHv2bI4ePcrXX3/N0aNH+fnPf86kSZMA6N27N/v372fz5s3MmTOH+Ph49u3bR2pqKvPnz8dkMrF+/Xp++9vfEhUVxcCBAzl8+DArVqxoUXnz8/OZP38+hmGQkZHB008/jcfj4d/+7d/47LPPMJlM3H333Tz88MMsXbqUlStXYrFY6N27N6+99lqrfGYtoeA4j/r/aVvrm5CINOZvLLE1/60dO3aMd955h4iICMrLy1mzZg0Wi4VNmzbx4osv8vrrrzd6z4EDB/jLX/7C6dOnueGGG/jZz35Gly5dGrxm9+7dFBQU0L17d26//XaKiopITU3lySefJC8vj549e5Kdnd3ich4/fpznnnuODz74gNjYWO655x4++OADkpKSOH78OAUFBQCcOnUKgIULF/Lxxx8TERHh29ZeNMbRhKwsN598UkJVVQ2ffFKi0BBpZe01ljhu3DjfvQzfffcdjzzyCKNGjeK3v/0t+/btO+97MjIyiIiIwGazkZCQwIkTJxq9Ji0tjaSkJMxmM3379uXIkSMcOHCAH/7wh/Ts2ROA8ePHt7icO3fuZOjQodjtdiwWC1lZWWzZsoWePXvy9ddf88tf/pINGzYQE1N3kc4///M/8/jjj7N69ep2vwRawSEiQdHUmGFrjyVGRUX5fn/ppZcYNmwYBQUFLF++vMm7qiMiIny/h4WF4fE0LlN4eHiD1/gbQ7kYcXFxrF27lqFDh7Jy5UqeeOIJAFasWMHEiRPZtWsXt956a5sd/3wUHCISFA6Hi8jIhjeetfVYosvlonv37gD8+c9/bvX99+rVi8OHD3PkyBEgsMH0tLQ0tmzZgtPpxOPxkJ+fz9ChQ3E6nXi9XsaOHcvMmTPZtWsXXq+X4uJi/uVf/oWnn34al8vF6dOnW70+TdEYh4gERTDGEidPnkxOTg6vvPIKGRkZrb7/yMhInn/+ee677z6ioqL8Xqn10Ucfcf311/seL1myhKeeeoo777zTNzg+ZswY9uzZw/Tp0313d8+aNQuPx8OUKVNwuVwYhsGDDz5IbGxsq9enKSbDMIx2O1qQaCGnlgu1+oLq3JoqKysbdA1dSiwWS7t055w+fZro6GgMw+Cpp57iqquu4uGHH27z455PS+t8vvPmbyEntThERFrRqlWr+Mtf/kJNTQ39+vXj/vvvD3aRWp2CQ0SkFT388MNBa2G0Fw2Oi4hIQBQcIiISEAWHiIgERMEhIiIBUXCISKdxxx13UFhY2GDb66+/jsPh8PuenTt3AnD//fefd96n2bNns3jxYr/H/uCDD/jiiy98j1966SU2bdoUQOnP71Kcgl3BISKdxvjx43nnnXcabHvnnXdaPGfUypUrL/hGuu8Hx4wZMxg+fPgF7etSp+AQkU5j7NixrF+/3rdw05EjR/j2228ZPHgwM2fO5JZbbuHGG2/k5ZdfPu/7Bw8ejNPpBOCVV17hxz/+MePHj+fgwYO+16xatYpbb72VzMxMHnroIdxuN0VFRaxdu5bf/e53jB49mq+++oqcnBzef/99AP73f/+Xm266iYyMDKZPn+6bI2vw4MG8/PLLjBkzhoyMDA4cONDiuubn55ORkcGoUaN47rnnAPB4POTk5DBq1CgyMjJ8raSlS5cycuRIMjMzmTx5coCfamO6j0NE2kS3X/+aLnv3tuo+a/r04bt///cmn4+PjyctLY0NGzYwZswY3nnnHW677TZMJhOzZs0iJiYGj8fD3Xffzd69e+nTp8959/PZZ5/x7rvvsnbtWmpra7n55ptJTU0F4JZbbuG+++4D4MUXX+RPf/oTDz74IKNHjyYzM5Nx48Y12FdVVRXTpk3jrbfeolevXkydOpUVK1bw0EMPAXULUH344YcsX76cxYsXNxlq52rpFOz181e19hTsanGISKdybnfVud1U7777LmPGjGHMmDHs27eP/fv3N7mPv//979x8881ERkYSExPD6NGjfc/t27ePf/3XfyUjI4M1a9Y0OTV7vYMHD9KzZ0969eoFwJ133snf//533/O33HILAKmpqb7JEZsT7CnY1eJoQpfPPsN+5514/vQnuO66YBdHpMPx1zJoS2PGjOE3v/kNu3btwu12k5qaytdff82iRYv47//+b+Li4sjJyaGqquqC9j9t2jSWLl1K3759eeutt/j4448vqrz1U7g3NX17IOqnYC8sLGTlypW8//77zJ49mxUrVrBlyxbWrl3Lq6++yvr16y8qQNTiaIphYK6ogGYWuReRS0t0dDTDhg1j+vTpvtaGy+UiKiqKbt26ceLECTZs2OB3H0OGDOHDDz/E7XZTUVHhW8scoKKigssvv5yamhrWrFnj2261Ws87tXmvXr04cuQIhw4dAmD16tUMGTLkouoY7CnY1eJognF2xTC8Xv8vFJFLzvjx45k0aZJvHe6+ffvSv39/hg8fTlJSEgMHDvT7/v79+3PbbbcxevRoEhISSEtL8z03Y8YMxo0bh91u59prr6WiogKA22+/nRkzZrB06VL+4z/+w/f6+rXNH3nkETweDwMGDAh44sMLnYL9l7/8ZZtMwa5p1Ztg2bOHxJtuouattzjx4x+3QakuTZpiPDRoWvXQ0FbTqqurqilqcYiInFe7dVW9//77FBQUYDKZuOKKK8jOzubkyZPMmzcPl8tFSkoKU6ZMwWKxUFNTw4IFC/jyyy+JiYkhJyeHxMREANasWUNBQQFms5kHHnigQROyVZnrMtV0kYNVIiKdTbu0OJxOJ3/961/Jzc1l9uzZeL1eNm/ezBtvvMHYsWOZP38+0dHRvmuPCwoKiI6OZv78+YwdO5ZVq1YB8M0337B582bmzJnD008/zdKlS319ea3NOBscKDhEWiwEer47pUDPW7t1VXm9Xqqrq/F4PFRXVxMXF8eePXt8VxeMHDmSoqIiALZu3crIkSOBuqsbdu/ejWEYFBUVMWzYMLp06UJiYiLdu3cP6E7LgKirSiRgZrM55MYROrra2lrM5sCioF26qmw2G7fddhuTJ08mPDycAQMGkJKSQlRUFGFn/0DbbDbfrf5OpxO73Q7UXdscFRWFy+XC6XTSu3fvBvutf8+51q1bx7p16wDIzc0lISEh8EJ/9x0AZsO4sPd3UBaLJaTqC6pzazIMA6fTeUmGh9frDbkWUUvq3KVLFy6//HJMJlOL99suwVFRUUFRURELFy4kKiqKOXPmsGPHjjY7XmZmJpmZmb7HF3L1SNh333E54K2tDakrbnSFUWho6zrXfyG8lOg8n59hGJSVlTXaHvSrqnbt2kViYiLdunXDYrEwePBg9u3bR2Vlpe9OSafTic1mA+paEvUV8Xg8VFZWEhMT02D799/T2oz69NUYh4hIA+0SHAkJCezfv58zZ85gGAa7du2iR48e9O3bly1btgBQWFhIeno6ANdff71vTv0tW7bQt29fTCYT6enpbN68mZqaGkpKSjh27BhXX3112xS6/huTgkNEpIF26arq3bs3Q4YM4cknnyQsLIwrr7ySzMxMrrvuOubNm8ebb77JVVddxahRowAYNWoUCxYsYMqUKVitVnJycgC44oorGDp0KNOnT8dsNjNp0qSAB3Va6n8+iOJBYOrjJt59IRGHw0VWlrtNjiUi0pHozvHzyMuL5Pczqvm6qjuPM5+FPE5kpJff//5Upw8P9QOHBtU5NFxMnYM+xtHR5ObGUFHVBQAzdZfjut1mcnNjglksEZFLgoLjPIqLw/Ce/WjC8DTYLiIS6hQc55GU5MFDXUicGxxJSRooFxFRcJyHw+Eiomvd7/VdVZGRXhwOVxBLJSJyadB6HOeRleUmrMYE08FCLcnJtbqqSkTkLLU4mnB7Vt3Kf//+21o++aREoSEicpaCoymaHVdE5LwUHE3RehwiIuel4GiKyVQ3X5WmVRcRaUDB4U9YmLqqRES+R8HhT1iYWhwiIt+j4PDDMJnU4hAR+R4Fhz9qcYiINKLg8MdsVotDROR7FBz+aHBcRKQRBYcfhtmsrioRke9RcPijrioRkUYUHP5ocFxEpBEFhz+6c1xEpBEFhx+GBsdFRBpRcPijrioRkUYUHP5ocFxEpBEFhz+6HFdEpBEFhx+GWhwiIo0oOPwJC9NCTiIi36Pg8EddVSIijSg4/FFXlYhIIwoOPwxdjisi0oiCwx+1OEREGlFw+KPgEBFpRMHRhLy8SHbs7krBehg0KJG8vMhgF0lE5JKg4DiPvLxIZs6Mpao6jDA8HD1qYebMWIWHiAgKjvPKzY3B7TbjIQwzdYPjbreZ3NyYIJdMRCT4LO11oNOnT7N48WKOHDmCyWRi8uTJJCUlMXfuXE6cOMFll13GtGnTsFqtGIbBsmXL2L59OxEREWRnZ5OSkgJAYWEheXl5AGRlZTFy5MhWL2txcRgAXsx0oabRdhGRUNZuLY5ly5aRlpbGvHnzeOmll0hOTiY/P5/+/fvz6quv0r9/f/Lz8wHYvn07x48f59VXX+Xhhx/mD3/4AwAVFRW8/fbbPP/88zz//PO8/fbbVFRUtHpZk5LqBsQ91HVVfX+7iEgoa5fgqKys5B//+AejRo0CwGKxEB0dTVFRESNGjABgxIgRFBUVAbB161aGDx+OyWTimmuu4fTp05SXl7Njxw5SU1OxWq1YrVZSU1PZsWNHq5fX4XARGelt0FUVGenF4XC1+rFERDqadumqKikpoVu3bixatIjDhw+TkpLCxIkTOXXqFPHx8QDExcVx6tQpAJxOJwkJCb732+12nE4nTqcTu93u226z2XA6na1e3qwsNwDhT5gIO+MhObkWh8Pl2y4iEsraJTg8Hg+HDh3iwQcfpHfv3ixbtszXLVXPZDJhMpla5Xjr1q1j3bp1AOTm5jYIoZZ6+GGwfGDGVOzlyy1eIPrsT+dmsVgu6PPqyFTn0KA6t+J+W32P52G327Hb7fTu3RuAIUOGkJ+fT2xsLOXl5cTHx1NeXk63bt2AupZEaWmp7/1lZWXYbDZsNht79+71bXc6nfTp06fR8TIzM8nMzPQ9PndfgYivrSWitvaC398RJSQkhFR9QXUOFapzYJKSkpp8rl3GOOLi4rDb7RQXFwOwa9cuevToQXp6Ohs3bgRg48aNDBw4EID09HQ2bdqEYRh88cUXREVFER8fT1paGjt37qSiooKKigp27txJWlpa2xVca46LiDTSbpfjPvjgg7z66qvU1taSmJhIdnY2hmEwd+5cCgoKfJfjAlx77bVs27aNqVOnEh4eTnZ2NgBWq5Wf/vSnzJo1C4A77rgDq9XadoU2mzFpkkMRkQZMhmEYwS5EW6tv6QQqfvJkuv7jHxwrLGzdAl3C1JwPDapzaOjQXVUdlaZVFxFpTMHhj8mkMQ4Rke9RcPijFoeISCMKDj/UVSUi0piCwx8t5CQi0oiCwx+zWS0OEZHvUXD4oxaHiEgjCg4/DN05LiLSiILDH3VViYg0ouDwR11VIiKNKDj80eW4IiKNKDj8MNTiEBFpRMHhj4JDRKQRBYc/6qoSEWmkxetx7N69m8TERBITEykvL2fVqlWYzWbuvfde4uLi2rCIQVS/Hodh1E14KCIiLW9xLF26FLO57uUrVqzA4/FgMplYsmRJmxUu2IywsLO/dPolS0REWqzFLQ6n00lCQgIej4edO3eyaNEiLBYLjzzySFuWL7jqWxkeT914h4iItLzFERkZycmTJ9m7dy89evSga9euANTW1rZZ4YIpLy+ShUtiAbhhmJ28vMggl0hE5NLQ4hbHzTffzKxZs6itrWXixIkAfP755yQnJ7dV2YImLy+SmTNjedzdBYBjxWZmzqwLkawsdzCLJiISdC0OjvHjxzNo0CDMZjPdu3cHwGaz8eijj7ZZ4YIlNzcGt9uM92yDLAwPFW4zubkxCg4RCXktDg5ouHj57t27MZvN9OnTp9ULFWzFxXWD4h7q/mvG22C7iEgoa/EYxzPPPMPnn38OQH5+Pq+88gqvvPIKeXl5bVa4YElKqrvp79wWx7nbRURCWYuD48iRI1xzzTUArF+/nmeeeYbnnnuOtWvXtlnhgsXhcBEZ6fW1OMLwEBnpxeFwBblkIiLB1+KuKuPsvQzHjx8HoEePHgCcPn26DYoVXPXjGMW/NOAUJHev5udPn9L4hogIAQTHj370I/7zP/+T8vJyBg4cCNSFSExMTJsVLpiystxEna4EB3zw39/iPXtBgIhIqGtxV9Vjjz1GVFQUP/zhD7nrrrsAKC4u5tZbb22zwgVd/Z3jmq9KRMSnxS2OmJgY7r333gbbrrvuulYv0KXEOHu3uEnBISLi0+LgqK2tJS8vj02bNlFeXk58fDzDhw8nKysLiyWgq3o7jvppRjS1uoiIT4v/4r/xxhscPHiQhx56iMsuu4wTJ06wevVqKisrfXeSdzr1waEWh4iIT4uDY8uWLbz00ku+wfCkpCSuuuoqZsyY0XmDo36MQy0OERGfFg+OGyE4tbhvjCME6y4i0pQWtziGDh3Kiy++yB133EFCQgKlpaWsXr2aoUOHtmX5gktjHCIijbQ4OCZMmMDq1atZunQp5eXl2Gw2hg0b1mmnVQfUVSUich4tDg6LxcLdd9/N3Xff7dtWXV3N/fffz4QJE9qkcEFX3+JQV5WIiM9FXUdrCnAdbq/Xi8PhwGaz4XA4KCkpYd68ebhcLlJSUpgyZQoWi4WamhoWLFjAl19+SUxMDDk5OSQmJgKwZs0aCgoKMJvNPPDAA6SlpV1MFfzyjXGoxSEi4tOu66H+z//8T4OFn9544w3Gjh3L/PnziY6OpqCgAICCggKio6OZP38+Y8eOZdWqVQB88803bN68mTlz5vD000+zdOlSvG15qay6qkREGmk2OHbv3t3kz549e1p8oLKyMrZt20ZGRgZQd5XWnj17GDJkCAAjR46kqKgIgK1btzJy5EgAhgwZwu7duzEMg6KiIoYNG0aXLl1ITEyke/fuHDhwINA6t1z9jY0KDhERn2a7ql577TW/zyckJLToQMuXL2fChAm43XUzzLpcLqKiogg7+63eZrPhdDoBcDqd2O12AMLCwoiKisLlcuF0Oundu7dvn+e+51zr1q1j3bp1AOTm5ra4jN9nstkAiLNaMS5wHx2NxWK54M+ro1KdQ4Pq3Ir7be4FCxcuvOiDfPrpp8TGxpKSkhJQK+VCZWZmkpmZ6XtcWlp6QfsJP32aBOBUWRnVF7iPjqb+UutQojqHBtU5MOeu+Pp97TLJ1L59+9i6dSvbt2+nuroat9vN8uXLqaysxOPxEBYWhtPpxHb2G77NZqOsrAy73Y7H46GyspKYmBjf9nrnvqdNnG0NaXBcROT/tMvg+L333svixYtZuHAhOTk59OvXj6lTp9K3b1+2bNkCQGFhIenp6QBcf/31FBYWAnVTnfTt2xeTyUR6ejqbN2+mpqaGkpISjh07xtVXX91m5TY0OC4i0khQp7W97777mDdvHm+++SZXXXUVo0aNAmDUqFEsWLCAKVOmYLVaycnJAeCKK65g6NChTJ8+HbPZzKRJkzCb2zD76gfHO/NNjiIiATIZITAJVXFx8QW9b9OrB/h/L44gi9V8kvwTHA5Xp18+Vv3AoUF1Dg1tNcbRrvdxdCR5eZG8PC8OADNejh61MHNmLHl5kcEtmIhIkCk4mpCbG0PFmXAALNR1VbndZnJzO+ca6yIiLaXgaEJxcRge6gbH64OjfruISChTcDQhKclD7dlrB8LwNNguIhLKFBxNcDhcWCLqPp76FkdkpBeHwxXMYomIBF1QL8e9lGVluYk6VQm/hC7UkJxcGxJXVYmINEctDj9uva0GgNznnHzySYlCQ0QEBYdfhqYcERFpRMHhj+4cFxFpRMHhj1ocIiKNKDj80CSHIiKNKTj8UVeViEgjCg5/zs68q64qEZH/o+Dwx2Sq665Si0NExEfB0RyLBbzeYJdCROSSoeBojsWCSS0OEREfBUdz1FUlItKAgqM56qoSEWlAwdEcdVWJiDSg4GhOWJhuABQROYeCw4+8vEiKSyz8+b/CGTQoUeuNi4ig4GhSXl4kM2fGcsZjIQwPR49amDkzVuEhIiFPwdGE3NwY3G4zHsJ8KwC63WZyc2OCXDIRkeBScDShuLhugsNaLL7gOHe7iEioUnA0ISmpbkC8lrququ9vFxEJVQqOJjgcLiIjvQ1aHJGRXhwOV5BLJiISXJZgF+BSVb++eNi/hWGpriU5uRaHw6V1x0Uk5Ck4/MjKctN9ZRjXRFXyyaqSYBdHROSSoK6q5ujOcRGRBhQczdGd4yIiDSg4mqPgEBFpQMHRHHVViYg0oOBojlocIiINKDiaoxaHiEgD7XI5bmlpKQsXLuTkyZOYTCYyMzO59dZbqaioYO7cuZw4cYLLLruMadOmYbVaMQyDZcuWsX37diIiIsjOziYlJQWAwsJC8vLyAMjKymLkyJFtW3iLRSsAioico12CIywsjPvvv5+UlBTcbjcOh4PU1FQKCwvp378/48ePJz8/n/z8fCZMmMD27ds5fvw4r776Kvv37+cPf/gDzz//PBUVFbz99tvk5uYC4HA4SE9Px2q1tlnZjfBwTDU1bbZ/EZGOpl26quLj430thsjISJKTk3E6nRQVFTFixAgARowYQVFREQBbt25l+PDhmEwmrrnmGk6fPk15eTk7duwgNTUVq9WK1WolNTWVHTt2tG3hw8PV4hAROUe73zleUlLCoUOHuPrqqzl16hTx8fEAxMXFcerUKQCcTicJCQm+99jtdpxOJ06nE7vd7ttus9lwOp2NjrFu3TrWrVsHQG5uboN9BcocHg4ez0XtoyOxWCwhU9d6qnNoUJ1bcb+tvkc/qqqqmD17NhMnTiQqKqrBcyaTCZPJ1CrHyczMJDMz0/e4tLT0gvaTlxdJ7F/CuamihutTzCExV1VCQsIFf14dleocGlTnwCQlJTX5XLtdVVVbW8vs2bO54YYbGDx4MACxsbGUl5cDUF5eTrdu3YC6lsS5lS0rK8Nms2Gz2SgrK/Ntdzqd2Gy2Nilv/QqA5RXhhFOtFQBFRM5ql+AwDIPFixeTnJzMuHHjfNvT09PZuHEjABs3bmTgwIG+7Zs2bcIwDL744guioqKIj48nLS2NnTt3UlFRQUVFBTt37iQtLa1Nyly/AmA14XShbnBcKwCKiLRTV9W+ffvYtGkTPXv2ZMaMGQDcc889jB8/nrlz51JQUOC7HBfg2muvZdu2bUydOpXw8HCys7MBsFqt/PSnP2XWrFkA3HHHHW12RVX9Sn81dCGc6kbbRURClckwDCPYhWhrxcXFAb9n0KBEjh618Bue4Rn+HRNewERyci2ffNJ5p1hXP3BoUJ1DQ4cf4+ho6lcArKELABZqtQKgiAhayKlJ9VdPfferLnASfvgDNzlPeTr9VVUiIs1RcPiRleUm0W2GmfC/649ixMYGu0giIkGnrqrmhIcDaNoREZGzFBzN6VI3xoGCQ0QEUHA0Ty0OEZEGFBzNUYtDRKQBBUczDLU4REQaUHA0p77FoanVRUQABUezNm6OAOAnY7oxaFCiJjkUkZCn4PAjLy+SeYu6AnV3jmuGXBERBYdfubkxuM7UjXHUT3SoGXJFJNQpOPwoLg6jmrrgqJ9avX67iEioUnD4kZTk8U1yeO7U6klJnmAVSUQk6BQcfjgcLsK61gVHfYtDM+SKSKjTJId+ZGW56eEyw1MQwRmSk2tDYt1xERF/FBzNuHW8BZ6CRfNKcN/ZeRdwEhFpKXVVNefsDYAm3QAoIgIoOJp3dsoRqqv9v05EJEQoOJpTP1eVgkNEBFBwNOvP70UDkPubcE05IiKCgsOvvLxIHv1FFABdqdKUIyIiKDj8ys2N4bQ7jCoi6EoVoClHREQUHH7UTy3iJpJI3I22i4iEIgWHH/VTi1TRtUFwaMoREQllCg4/HA4XUVEGbiJ9XVWackREQp3uHPcjK8tNTEwMNT+PJLLWrSlHRERQcDTrnnu8MMfCDxPKGbZSU46IiKirqhl/+pOZbZ93Y0uBR/dxiIig4PArLy+S7OwwSqtjicGl+zhERFBw+JWbG0NlpYnv6EY3vgN0H4eIiILDj/r7Nc4NjnO3i4iEIgWHH/X3a3w/OAB1V4lIyDIZhmEEuxCB2rFjB8uWLcPr9ZKRkcH48eP9vr64uPiCjpOXF8kvfhHHLO9z/I5fEc4Zajg7zTod7mMTkRD1s5+d5oUXvmv+hedISkpq8rkO1+Lwer0sXbqUp556irlz5/LRRx/xzTfftMmxsrLceL3wDT0AqCaCBE6cfdakH/3oRz8d4mfFimhmzepGa+lw93EcOHCA7t27c/nllwMwbNgwioqK6NGjR5sd8whX+H4/QSJ7+ec2O9a5DEztchwR6Zz+yi3M4GXAxKpV0QG3OprS4YLD6XRit9t9j+12O/v372/wmnXr1rFu3ToAcnNzSUhIuKhjbmI4q8liIEV8xL8QRtvPVWVSV5iIXKSjJPt+93i46L+F9TpccLREZmYmmZmZvselpaUXvC+r9QdUVHThDla3RtFERIIiLCywv4WdaozDZrNRVlbme1xWVobNZmuz4y1Y4EED4SLSsRncd9/pVttbh2tx9OrVi2PHjlFSUoLNZmPz5s1MnTq1zY53zz1eXC4X06fHUlOjMQcR6Xgu5Koqfzrk5bjbtm3jj3/8I16vlxtvvJGsrCy/r7/Qy3Ghrk/wYrq6OppQqy+ozqFCdQ6Mv66qDtfiALjuuuu47rrrgl0MEZGQ1OHGOEREJLgUHCIiEhAFh4iIBETBISIiAemQV1WJiEjwqMXRDIfDEewitKtQqy+ozqFCdW49Cg4REQmIgkNERAKi4GjGuZMlhoJQqy+ozqFCdW49GhwXEZGAqMUhIiIBUXCIiEhAOuQkh+1hx44dLFu2DK/XS0ZGBuPHjw92kVpFaWkpCxcu5OTJk5hMJjIzM7n11lupqKhg7ty5nDhxgssuu4xp06ZhtVoxDINly5axfft2IiIiyM7OJiUlJdjVCJjX68XhcGCz2XA4HJSUlDBv3jxcLhcpKSlMmTIFi8VCTU0NCxYs4MsvvyQmJoacnBwSExODXfwLcvr0aRYvXsyRI0cwmUxMnjyZpKSkTn2e33//fQoKCjCZTFxxxRVkZ2dz8uTJTnWuFy1axLZt24iNjWX27NkAF/Tvt7CwkLy8PACysrIYOXJkywthSCMej8d4/PHHjePHjxs1NTXGE088YRw5ciTYxWoVTqfTOHjwoGEYhlFZWWlMnTrVOHLkiLFy5UpjzZo1hmEYxpo1a4yVK1cahmEYn376qfHcc88ZXq/X2LdvnzFr1qxgFf2ivPfee8a8efOMF154wTAMw5g9e7bxt7/9zTAMw1iyZInx4YcfGoZhGB988IGxZMkSwzAM429/+5sxZ86c4BS4FcyfP99Yt26dYRiGUVNTY1RUVHTq81xWVmZkZ2cbZ86cMQyj7hxv2LCh053rPXv2GAcPHjSmT5/u2xboeXW5XMZjjz1muFyuBr+3lLqqzuPAgQN0796dyy+/HIvFwrBhwygqKgp2sVpFfHy87xtHZGQkycnJOJ1OioqKGDFiBAAjRozw1Xfr1q0MHz4ck8nENddcw+nTpykvLw9a+S9EWVkZ27ZtIyMjAwDDMNizZw9DhgwBYOTIkQ3qW//Na8iQIezevRujA14/UllZyT/+8Q9GjRoFgMViITo6ulOfZ6hrWVZXV+PxeKiuriYuLq7Tnes+ffpgtVobbAv0vO7YsYPU1FSsVitWq5XU1FR27NjR4jKoq+o8nE4ndrvd99hut7N///4glqhtlJSUcOjQIa6++mpOnTpFfHw8AHFxcZw6dQqo+yzOXeDebrfjdDp9r+0Ili9fzoQJE3C73QC4XC6ioqIICwsD6pYjdjqdQMNzHxYWRlRUFC6Xi27dugWn8BeopKSEbt26sWjRIg4fPkxKSgoTJ07s1OfZZrNx2223MXnyZMLDwxkwYAApKSmd/lwDAZ/X7/+NO/dzaQm1OEJUVVUVs2fPZuLEiURFRTV4zmQyYTJ1jmVyP/30U2JjYztkf/3F8Hg8HDp0iJtuuonf//73REREkJ+f3+A1nek8Q10/f1FREQsXLmTJkiVUVVUF9C26s2iP86oWx3nYbDbKysp8j8vKyrDZbEEsUeuqra1l9uzZ3HDDDQwePBiA2NhYysvLiY+Pp7y83Pety2azNVh6sqN9Fvv27WPr1q1s376d6upq3G43y5cvp7KyEo/HQ1hYGE6n01en+nNvt9vxeDxUVlYSExMT5FoEzm63Y7fb6d27N1DXFZOfn99pzzPArl27SExM9NVp8ODB7Nu3r9Ofawj836/NZmPv3r2+7U6nkz59+rT4eGpxnEevXr04duwYJSUl1NbWsnnzZtLT04NdrFZhGAaLFy8mOTmZcePG+banp6ezceNGADZu3MjAgQN92zdt2oRhGHzxxRdERUV1qO6Le++9l8WLF7Nw4UJycnLo168fU6dOpW/fvmzZsgWou7qk/vxef/31FBYWArBlyxb69u3bIb+Vx8XFYbfbKS4uBur+qPbo0aPTnmeoW197//79nDlzBsMwfHXu7OcaAv/3m5aWxs6dO6moqKCiooKdO3eSlpbW4uPpzvEmbNu2jT/+8Y94vV5uvPFGsrKygl2kVvH555/z61//mp49e/r+kdxzzz307t2buXPnUlpa2uhyvqVLl7Jz507Cw8PJzs6mV69eQa7FhdmzZw/vvfceDoeDb7/9lnnz5lFRUcFVV13FlClT6NKlC9XV1SxYsIBDhw5htVrJycnh8ssvD3bRL8hXX33F4sWLqa2tJTExkezsbAzD6NTn+c9//jObN28mLCyMK6+8kkcffRSn09mpzvW8efPYu3cvLpeL2NhY7rrrLgYOHBjweS0oKGDNmjVA3eW4N954Y4vLoOAQEZGAqKtKREQCouAQEZGAKDhERCQgCg4REQmIgkNERAKi4BC5RN11110cP3482MUQaUR3jou00GOPPcbJkycxm//v+9bIkSOZNGlSEEsl0v4UHCIBePLJJ0lNTQ12MUSCSsEhcpEKCwtZv349V155JZs2bSI+Pp5JkybRv39/oG4eoNdff53PP/8cq9XK7bffTmZmJlA3DXh+fj4bNmzg1KlT/OAHP2DGjBm+GU0/++wznn/+eb777jt+/OMfM2nSJEwmE8ePH+e1117jq6++wmKx0K9fP6ZNmxa0z0BCi4JDpBXs37+fwYMHs3TpUj755BNefvllFi5ciNVq5ZVXXuGKK65gyZIlFBcX8+yzz9K9e3f69evH+++/z0cffcSsWbP4wQ9+wOHDh4mIiPDtd9u2bbzwwgu43W6efPJJ0tPTSUtL480332TAgAE888wz1NbW8uWXXwax9hJqFBwiAXjppZd8azsATJgwAYvFQmxsLGPHjsVkMjFs2DDee+89tm3bRp8+ffj8889xOByEh4dz5ZVXkpGRwcaNG+nXrx/r169nwoQJJCUlAXDllVc2ON748eOJjo4mOjqavn378tVXX5GWlobFYuHEiROUl5djt9v5p3/6p/b8GCTEKThEAjBjxoxGYxyFhYXYbLYGM6tedtllOJ1OysvLsVqtREZG+p5LSEjg4MGDQN001/4m1ouLi/P9HhERQVVVFVAXWG+++SZPPfUU0dHRjBs3zrfan0hbU3CItAKn04lhGL7wKC0tJT09nfj4eCoqKnC73b7wKC0t9a0JYbfb+fbbb+nZs2dAx4uLi+PRRx8F6mY8fvbZZ+nTpw/du3dvxVqJnJ/u4xBpBadOneKvf/0rtbW1fPzxxxw9epRrr72WhIQEfvSjH/Ff//VfVFdXc/jwYTZs2MANN9wAQEZGBm+99RbHjh3DMAwOHz6My+Vq9ngff/yxb7Gx6OhogA67loR0PGpxiATgxRdfbHAfR2pqKgMHDqR3794cO3aMSZMmERcXx/Tp032ryf3iF7/g9ddf55FHHsFqtXLnnXf6urvGjRtHTU0Nv/vd73C5XCQnJ/PEE080W46DBw/6VjKMi4vjgQce6BBrSUjnoPU4RC5S/eW4zz77bLCLItIu1FUlIiIBUXCIiEhA1FUlIiIBUYtDREQCouAQEZGAKDhERCQgCg4REQmIgkNERALy/wGDgK3cZg0KSAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = Ide_AE_history.history['loss']\n",
    "val_loss = Ide_AE_history.history['val_loss']\n",
    "\n",
    "epochs = range(epochs_number)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for one-to-one map layer 26.331503918560283\n"
     ]
    }
   ],
   "source": [
    "p_data=Ide_AE.predict(x_test)\n",
    "numbers=x_test.shape[0]*x_test.shape[1]\n",
    "\n",
    "print(\"MSE for one-to-one map layer\",np.sum(np.power(np.array(p_data)-x_test,2))/numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "key_number=64\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_number=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_features=F.top_k_keepWeights_1(Ide_AE.get_layer(index=1).get_weights()[0],key_number)\n",
    "\n",
    "selected_position_list=np.where(key_features>0)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Classifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy 1.0\n",
      "Training accuracy 1.0\n",
      "Testing accuracy 0.7368421052631579\n",
      "Testing accuracy 0.7368421052631579\n"
     ]
    }
   ],
   "source": [
    "train_feature=C_train_x\n",
    "train_label=C_train_y\n",
    "test_feature=C_test_x\n",
    "test_label=C_test_y\n",
    "p_seed=seed\n",
    "F.ETree(train_feature,train_label,test_feature,test_label,p_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149, 64)\n",
      "(38, 64)\n",
      "Training accuracy 1.0\n",
      "Training accuracy 1.0\n",
      "Testing accuracy 0.6578947368421053\n",
      "Testing accuracy 0.6578947368421053\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_feature_=np.multiply(C_train_x, key_features)\n",
    "train_feature=F.compress_zero_withkeystructure(train_feature_,selected_position_list)\n",
    "print(train_feature.shape)\n",
    "train_label=C_train_y\n",
    "\n",
    "test_feature_=np.multiply(C_test_x, key_features)\n",
    "test_feature=F.compress_zero_withkeystructure(test_feature_,selected_position_list)\n",
    "print(test_feature.shape)\n",
    "test_label=C_test_y\n",
    "\n",
    "p_seed=seed\n",
    "F.ETree(train_feature,train_label,test_feature,test_label,p_seed)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Reconstruction loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def mse_check(train, test):\n",
    "    LR = LinearRegression(n_jobs = -1)\n",
    "    LR.fit(train[0], train[1])\n",
    "    MSELR = ((LR.predict(test[0]) - test[1]) ** 2).mean()\n",
    "    return MSELR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149, 64)\n",
      "(38, 64)\n",
      "0.09588378118386018\n"
     ]
    }
   ],
   "source": [
    "train_feature_=np.multiply(C_train_x, key_features)\n",
    "C_train_selected_x=F.compress_zero_withkeystructure(train_feature_,selected_position_list)\n",
    "print(C_train_selected_x.shape)\n",
    "\n",
    "test_feature_=np.multiply(C_test_x, key_features)\n",
    "C_test_selected_x=F.compress_zero_withkeystructure(test_feature_,selected_position_list)\n",
    "print(C_test_selected_x.shape)\n",
    "\n",
    "\n",
    "train_feature_tuple=(C_train_selected_x,C_train_x)\n",
    "test_feature_tuple=(C_test_selected_x,C_test_x)\n",
    "\n",
    "reconstruction_loss=mse_check(train_feature_tuple, test_feature_tuple)\n",
    "print(reconstruction_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
